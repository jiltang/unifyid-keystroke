{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['user', 'entry', 'character', 'next_char', 'times', 'digraph',\n",
      "       'phrasetime', 'del', 'err'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>entry</th>\n",
       "      <th>character</th>\n",
       "      <th>digraph</th>\n",
       "      <th>phrasetime</th>\n",
       "      <th>del</th>\n",
       "      <th>err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.303296</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.013945</td>\n",
       "      <td>0.303296</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001499</td>\n",
       "      <td>0.303296</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.001758</td>\n",
       "      <td>0.303296</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0.015259</td>\n",
       "      <td>0.303296</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  entry  character   digraph  phrasetime  del  err\n",
       "0     1      1          8  0.000000    0.303296  1.0  0.0\n",
       "1     1      1         10  0.013945    0.303296  1.0  0.0\n",
       "2     1      1          1  0.001499    0.303296  1.0  0.0\n",
       "3     1      1          6  0.001758    0.303296  1.0  0.0\n",
       "4     1      1         23  0.015259    0.303296  1.0  0.0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat = pd.read_csv(\"qualified_clean.csv\")\n",
    "dat['times'] = pd.to_datetime(dat['times'])\n",
    "dat = dat.sort_values(by=['user', 'entry', 'times'])\n",
    "dat = dat.reset_index(drop=True)\n",
    "print(dat.columns)\n",
    "dat = dat.drop(['times', 'next_char'], axis=1)\n",
    "dat = dat.dropna()\n",
    "dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "(14120, 100, 7) (14120,)\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 100\n",
    "\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "for user in np.unique(dat['user']):\n",
    "    u_x = dat[dat['user'] == user]\n",
    "    u_e = []\n",
    "    for entry in np.unique(u_x['entry']):\n",
    "        new_entry = u_x[u_x['entry'] == entry]\n",
    "        new_entry = np.pad(new_entry, [(MAX_LEN - new_entry.shape[0], 0), (0, 0)], mode='constant')\n",
    "        u_e.append(new_entry)\n",
    "    x.append(np.stack(u_e))\n",
    "    num_entries = len(u_e)\n",
    "    y.append(np.ones([num_entries]) * user)\n",
    "    print(user)\n",
    "\n",
    "x = np.concatenate(x)\n",
    "y = np.concatenate(y)\n",
    "\n",
    "print(x.shape, y.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.utils.data.TensorDataset(torch.Tensor(x), torch.Tensor(y))\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=500, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(7, 26)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_simple = x[:, -1, :]\n",
    "        outputs = self.linear(x_simple)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUModel(torch.nn.Module):\n",
    "    def __init__(self, hidden_size=100):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.gru = torch.nn.GRU(7, hidden_size, num_layers=2)\n",
    "        self.linear = torch.nn.Linear(10 * hidden_size, 26)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x[:, -10:, :]\n",
    "        x = torch.transpose(x, 0, 1) # now (seq_len, batch, dim)\n",
    "#         print(x.shape)\n",
    "        gruOut, gruHN = self.gru(x)\n",
    "#         print(gruHN)\n",
    "        gruOut = torch.transpose(gruOut, 0, 1) # now (batch, seq_len, dim)\n",
    "        gruOut = gruOut.reshape(gruOut.size(0), -1)\n",
    "#         print(last_layer.shape)\n",
    "        out = self.linear(gruOut)\n",
    "        \n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "epoch 0, loss 93.57019805908203\n",
      "14120 786 0.0556657223796034\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "epoch 1, loss 92.33280181884766\n",
      "14120 923 0.06536827195467422\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "epoch 2, loss 92.00379180908203\n",
      "14120 917 0.06494334277620396\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "epoch 3, loss 91.70684051513672\n",
      "14120 923 0.06536827195467422\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "epoch 4, loss 91.4397964477539\n",
      "14120 935 0.06621813031161473\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "epoch 5, loss 91.27296447753906\n",
      "14120 1040 0.07365439093484419\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "epoch 6, loss 90.79420471191406\n",
      "14120 1042 0.07379603399433428\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "epoch 7, loss 90.54869842529297\n",
      "14120 1099 0.0778328611898017\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "epoch 8, loss 90.3297348022461\n",
      "14120 1136 0.08045325779036827\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "epoch 9, loss 90.29293823242188\n",
      "14120 1184 0.08385269121813031\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "epoch 10, loss 89.68816375732422\n",
      "14120 1188 0.08413597733711048\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "epoch 11, loss 89.60015106201172\n",
      "14120 1315 0.09313031161473088\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "epoch 12, loss 89.51891326904297\n",
      "14120 1065 0.07542492917847025\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "epoch 13, loss 89.2352294921875\n",
      "14120 1269 0.08987252124645892\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "epoch 14, loss 89.29539489746094\n",
      "14120 1242 0.08796033994334278\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "epoch 15, loss 89.02649688720703\n",
      "14120 1268 0.08980169971671388\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "epoch 16, loss 89.13980102539062\n",
      "14120 1288 0.09121813031161473\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "epoch 17, loss 88.7921142578125\n",
      "14120 1293 0.09157223796033995\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "epoch 18, loss 88.83324432373047\n",
      "14120 1148 0.08130311614730878\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "epoch 19, loss 88.60965728759766\n",
      "14120 1332 0.0943342776203966\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "epoch 20, loss 89.30438995361328\n",
      "14120 1146 0.0811614730878187\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "epoch 21, loss 88.91309356689453\n",
      "14120 1171 0.08293201133144476\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "epoch 22, loss 88.54270935058594\n",
      "14120 1214 0.08597733711048158\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "epoch 23, loss 88.89749908447266\n",
      "14120 1137 0.08052407932011331\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "epoch 24, loss 88.50467681884766\n",
      "14120 1287 0.09114730878186969\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "epoch 25, loss 89.20288848876953\n",
      "14120 1180 0.08356940509915015\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "epoch 26, loss 89.14990234375\n",
      "14120 1201 0.08505665722379603\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "epoch 27, loss 88.77476501464844\n",
      "14120 1230 0.08711048158640226\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "epoch 28, loss 88.8301773071289\n",
      "14120 1158 0.08201133144475921\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "epoch 29, loss 88.47797393798828\n",
      "14120 1202 0.08512747875354108\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-138-e3714c22bd30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mloss_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \"\"\"\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = GRUModel()\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction='mean')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01) \n",
    "\n",
    "PRINT_RATE = 20\n",
    "\n",
    "## Optimization Loop\n",
    "\n",
    "for epoch in range(1000): \n",
    "    loss_sum = 0\n",
    "    total, correct = 0, 0\n",
    "    for idx, (x_batch, y_batch) in enumerate(dataloader):\n",
    "        print(idx)\n",
    "        y_pred = model(x_batch)\n",
    "#         print(y_pred[:5])\n",
    "#         print(\"y_pred shape is\", y_pred.shape)\n",
    "#         print(\"y_batch shape is\", y_batch.shape)\n",
    "        loss = criterion(y_pred, y_batch.long())\n",
    "        optimizer.zero_grad() \n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        loss_sum += loss\n",
    "        y_pred_i = torch.argmax(y_pred, dim=-1)\n",
    "        correct += torch.sum(torch.eq(y_pred_i, y_batch)).item()\n",
    "        total += len(y_batch)\n",
    "    print('epoch {}, loss {}'.format(epoch, loss_sum.item())) \n",
    "#     print(y_pred_i[:1])\n",
    "    print(total, correct, correct/total)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>entry</th>\n",
       "      <th>character_1</th>\n",
       "      <th>character_2</th>\n",
       "      <th>character_3</th>\n",
       "      <th>character_4</th>\n",
       "      <th>character_5</th>\n",
       "      <th>character_6</th>\n",
       "      <th>character_7</th>\n",
       "      <th>character_8</th>\n",
       "      <th>...</th>\n",
       "      <th>digraph_35</th>\n",
       "      <th>digraph_36</th>\n",
       "      <th>digraph_37</th>\n",
       "      <th>digraph_38</th>\n",
       "      <th>digraph_39</th>\n",
       "      <th>digraph_40</th>\n",
       "      <th>digraph_41</th>\n",
       "      <th>del</th>\n",
       "      <th>err</th>\n",
       "      <th>phrasetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004770</td>\n",
       "      <td>0.017470</td>\n",
       "      <td>0.016675</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.017868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.303296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016757</td>\n",
       "      <td>0.008350</td>\n",
       "      <td>0.009592</td>\n",
       "      <td>0.018797</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>0.001690</td>\n",
       "      <td>0.006765</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.305861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001077</td>\n",
       "      <td>0.001366</td>\n",
       "      <td>0.005116</td>\n",
       "      <td>0.002441</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>0.008573</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.305620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014780</td>\n",
       "      <td>0.001881</td>\n",
       "      <td>0.001936</td>\n",
       "      <td>0.008713</td>\n",
       "      <td>0.007559</td>\n",
       "      <td>0.009240</td>\n",
       "      <td>0.011532</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.272646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004859</td>\n",
       "      <td>0.016099</td>\n",
       "      <td>0.008431</td>\n",
       "      <td>0.004978</td>\n",
       "      <td>0.007762</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.336338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  entry  character_1  character_2  character_3  character_4  \\\n",
       "0     1      1            8           10            1            6   \n",
       "1     1      2            8           10            1            6   \n",
       "2     1      3            8           10            1            6   \n",
       "3     1      4            8           10            1            6   \n",
       "4     1      5            8           10            1            6   \n",
       "\n",
       "   character_5  character_6  character_7  character_8  ...  digraph_35  \\\n",
       "0           23           21           13           10  ...    0.004770   \n",
       "1           23           21           13           10  ...    0.016757   \n",
       "2           23           21           13           13  ...    0.001077   \n",
       "3           23           21           13           13  ...    0.014780   \n",
       "4           23           21           13           10  ...    0.004859   \n",
       "\n",
       "   digraph_36  digraph_37  digraph_38  digraph_39  digraph_40  digraph_41  \\\n",
       "0    0.017470    0.016675    0.001636    0.017868         NaN         NaN   \n",
       "1    0.008350    0.009592    0.018797    0.000709    0.001690    0.006765   \n",
       "2    0.001366    0.005116    0.002441    0.001095    0.008573         NaN   \n",
       "3    0.001881    0.001936    0.008713    0.007559    0.009240    0.011532   \n",
       "4    0.016099    0.008431    0.004978    0.007762         NaN         NaN   \n",
       "\n",
       "   del  err  phrasetime  \n",
       "0    1    0    0.303296  \n",
       "1    2    1    0.305861  \n",
       "2    2    1    0.305620  \n",
       "3    2    0    0.272646  \n",
       "4    1    0    0.336338  \n",
       "\n",
       "[5 rows x 128 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat = pd.read_csv(\"clean_wide.csv\")\n",
    "dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16815, 128)\n"
     ]
    }
   ],
   "source": [
    "df = dat.to_numpy()\n",
    "print(df.shape)\n",
    "df = np.nan_to_num(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16815, 126)\n",
      "(16815,)\n",
      "[[ 8.         10.          1.         ...  1.          0.\n",
      "   0.30329609]\n",
      " [ 8.         10.          1.         ...  2.          1.\n",
      "   0.305861  ]\n",
      " [ 8.         10.          1.         ...  2.          1.\n",
      "   0.30562019]\n",
      " ...\n",
      " [ 8.         10.          1.         ...  2.          1.\n",
      "   1.5771718 ]\n",
      " [ 8.         10.          1.         ...  2.          1.\n",
      "   1.55091119]\n",
      " [ 8.         10.          1.         ...  1.          0.\n",
      "   1.48837495]]\n",
      "[ 1.  1.  1. ... 25. 25. 25.]\n"
     ]
    }
   ],
   "source": [
    "x = df[:,2:]\n",
    "y = df[:,0]\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.utils.data.TensorDataset(torch.Tensor(x), torch.Tensor(y))\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=500, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(126, 400),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(400, 400),\n",
    "            nn.ReLU(True),\n",
    "             nn.Linear(400, 400),\n",
    "             nn.ReLU(True),\n",
    "             nn.Linear(400, 400),\n",
    "             nn.ReLU(True),\n",
    "            nn.Linear(400, 400),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(400, 26)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss 110.45457458496094\n",
      "16815 791 0.04704133214391912\n",
      "epoch 1, loss 109.63056945800781\n",
      "16815 1008 0.059946476360392506\n",
      "epoch 2, loss 108.92058563232422\n",
      "16815 1250 0.07433838834374071\n",
      "epoch 3, loss 108.32846069335938\n",
      "16815 1435 0.08534046981861433\n",
      "epoch 4, loss 107.88009643554688\n",
      "16815 1425 0.0847457627118644\n",
      "epoch 5, loss 107.47245788574219\n",
      "16815 1419 0.08438893844781445\n",
      "epoch 6, loss 107.0788345336914\n",
      "16815 1510 0.08980077311923877\n",
      "epoch 7, loss 106.6823959350586\n",
      "16815 1571 0.09342848647041332\n",
      "epoch 8, loss 106.26136016845703\n",
      "16815 1589 0.09449895926256319\n",
      "epoch 9, loss 105.83038330078125\n",
      "16815 1669 0.0992566161165626\n",
      "epoch 10, loss 105.41015625\n",
      "16815 1736 0.10324115373178709\n",
      "epoch 11, loss 105.01292419433594\n",
      "16815 1717 0.10211121022896223\n",
      "epoch 12, loss 104.69383239746094\n",
      "16815 1845 0.10972346119536129\n",
      "epoch 13, loss 104.37446594238281\n",
      "16815 1849 0.10996134403806125\n",
      "epoch 14, loss 104.0894775390625\n",
      "16815 1860 0.11061552185548618\n",
      "epoch 15, loss 103.81623840332031\n",
      "16815 1853 0.11019922688076123\n",
      "epoch 16, loss 103.56893157958984\n",
      "16815 1846 0.10978293190603627\n",
      "epoch 17, loss 103.31393432617188\n",
      "16815 1894 0.11263752601843592\n",
      "epoch 18, loss 103.0835952758789\n",
      "16815 1867 0.11103181683021113\n",
      "epoch 19, loss 102.86067199707031\n",
      "16815 1920 0.11418376449598573\n",
      "epoch 20, loss 102.63520050048828\n",
      "16815 2042 0.12143919119833482\n",
      "epoch 21, loss 102.40872192382812\n",
      "16815 2036 0.12108236693428487\n",
      "epoch 22, loss 102.19943237304688\n",
      "16815 2058 0.1223907225691347\n",
      "epoch 23, loss 102.01512145996094\n",
      "16815 2059 0.12245019327980969\n",
      "epoch 24, loss 101.84188842773438\n",
      "16815 2051 0.12197442759440975\n",
      "epoch 25, loss 101.6753158569336\n",
      "16815 2043 0.1214986619090098\n",
      "epoch 26, loss 101.55209350585938\n",
      "16815 2058 0.1223907225691347\n",
      "epoch 27, loss 101.3857192993164\n",
      "16815 2072 0.1232233125185846\n",
      "epoch 28, loss 101.25077819824219\n",
      "16815 2096 0.12465060957478442\n",
      "epoch 29, loss 101.171142578125\n",
      "16815 2129 0.12661314302705917\n",
      "epoch 30, loss 101.01594543457031\n",
      "16815 2138 0.12714837942313412\n",
      "epoch 31, loss 100.94478607177734\n",
      "16815 2133 0.12685102586975913\n",
      "epoch 32, loss 100.8299331665039\n",
      "16815 2136 0.12702943800178412\n",
      "epoch 33, loss 100.75349426269531\n",
      "16815 2126 0.1264347308950342\n",
      "epoch 34, loss 100.64173889160156\n",
      "16815 2140 0.12726732084448408\n",
      "epoch 35, loss 100.59512329101562\n",
      "16815 2141 0.12732679155515908\n",
      "epoch 36, loss 100.50269317626953\n",
      "16815 2124 0.12631578947368421\n",
      "epoch 37, loss 100.43157958984375\n",
      "16815 2126 0.1264347308950342\n",
      "epoch 38, loss 100.36772155761719\n",
      "16815 2125 0.1263752601843592\n",
      "epoch 39, loss 100.30438232421875\n",
      "16815 2129 0.12661314302705917\n",
      "epoch 40, loss 100.26568603515625\n",
      "16815 2122 0.12619684805233422\n",
      "epoch 41, loss 100.18163299560547\n",
      "16815 2129 0.12661314302705917\n",
      "epoch 42, loss 100.14492797851562\n",
      "16815 2130 0.12667261373773417\n",
      "epoch 43, loss 100.10606384277344\n",
      "16815 2127 0.12649420160570918\n",
      "epoch 44, loss 100.07188415527344\n",
      "16815 2090 0.12429378531073447\n",
      "epoch 45, loss 100.01040649414062\n",
      "16815 2118 0.12595896520963426\n",
      "epoch 46, loss 99.9524917602539\n",
      "16815 2139 0.1272078501338091\n",
      "epoch 47, loss 99.89358520507812\n",
      "16815 2163 0.12863514719000893\n",
      "epoch 48, loss 99.89127349853516\n",
      "16815 2114 0.12572108236693427\n",
      "epoch 49, loss 99.8375473022461\n",
      "16815 2149 0.12780255724055903\n",
      "epoch 50, loss 99.77986907958984\n",
      "16815 2106 0.12524531668153435\n",
      "epoch 51, loss 99.76463317871094\n",
      "16815 2131 0.12673208444840917\n",
      "epoch 52, loss 99.67666625976562\n",
      "16815 2151 0.12792149866190902\n",
      "epoch 53, loss 99.65592956542969\n",
      "16815 2157 0.12827832292595898\n",
      "epoch 54, loss 99.61994934082031\n",
      "16815 2165 0.1287540886113589\n",
      "epoch 55, loss 99.53169250488281\n",
      "16815 2179 0.1295866785608088\n",
      "epoch 56, loss 99.484619140625\n",
      "16815 2181 0.1297056199821588\n",
      "epoch 57, loss 99.45170593261719\n",
      "16815 2168 0.1289325007433839\n",
      "epoch 58, loss 99.43519592285156\n",
      "16815 2193 0.1304192685102587\n",
      "epoch 59, loss 99.37498474121094\n",
      "16815 2210 0.13143027059173357\n",
      "epoch 60, loss 99.3565673828125\n",
      "16815 2175 0.12934879571810884\n",
      "epoch 61, loss 99.31636810302734\n",
      "16815 2205 0.1311329170383586\n",
      "epoch 62, loss 99.24166870117188\n",
      "16815 2226 0.13238180196253346\n",
      "epoch 63, loss 99.21878051757812\n",
      "16815 2229 0.13256021409455843\n",
      "epoch 64, loss 99.1930160522461\n",
      "16815 2214 0.13166815343443355\n",
      "epoch 65, loss 99.0947494506836\n",
      "16815 2248 0.13369015759738329\n",
      "epoch 66, loss 99.07476806640625\n",
      "16815 2270 0.13499851323223314\n",
      "epoch 67, loss 99.04145050048828\n",
      "16815 2235 0.13291703835860838\n",
      "epoch 68, loss 98.98218536376953\n",
      "16815 2280 0.13559322033898305\n",
      "epoch 69, loss 98.94316864013672\n",
      "16815 2236 0.13297650906928338\n",
      "epoch 70, loss 98.87928009033203\n",
      "16815 2273 0.1351769253642581\n",
      "epoch 71, loss 98.81465148925781\n",
      "16815 2253 0.13398751115075824\n",
      "epoch 72, loss 98.80917358398438\n",
      "16815 2291 0.13624739815640796\n",
      "epoch 73, loss 98.77066802978516\n",
      "16815 2247 0.1336306868867083\n",
      "epoch 74, loss 98.77619934082031\n",
      "16815 2267 0.13482010110020815\n",
      "epoch 75, loss 98.68199157714844\n",
      "16815 2292 0.13630686886708296\n",
      "epoch 76, loss 98.71019744873047\n",
      "16815 2261 0.1344632768361582\n",
      "epoch 77, loss 98.59879302978516\n",
      "16815 2284 0.135831103181683\n",
      "epoch 78, loss 98.64693450927734\n",
      "16815 2260 0.1344038061254832\n",
      "epoch 79, loss 98.53610229492188\n",
      "16815 2274 0.1352363960749331\n",
      "epoch 80, loss 98.45518493652344\n",
      "16815 2301 0.1368421052631579\n",
      "epoch 81, loss 98.461669921875\n",
      "16815 2270 0.13499851323223314\n",
      "epoch 82, loss 98.45584106445312\n",
      "16815 2291 0.13624739815640796\n",
      "epoch 83, loss 98.37350463867188\n",
      "16815 2300 0.1367826345524829\n",
      "epoch 84, loss 98.31957244873047\n",
      "16815 2281 0.13565269104965805\n",
      "epoch 85, loss 98.4282455444336\n",
      "16815 2244 0.13345227475468333\n",
      "epoch 86, loss 98.38998413085938\n",
      "16815 2301 0.1368421052631579\n",
      "epoch 87, loss 98.28785705566406\n",
      "16815 2268 0.13487957181088314\n",
      "epoch 88, loss 98.26541900634766\n",
      "16815 2251 0.13386856972940828\n",
      "epoch 89, loss 98.35010528564453\n",
      "16815 2283 0.13577163247100804\n",
      "epoch 90, loss 98.18341827392578\n",
      "16815 2289 0.136128456735058\n",
      "epoch 91, loss 98.27332305908203\n",
      "16815 2280 0.13559322033898305\n",
      "epoch 92, loss 98.24671936035156\n",
      "16815 2305 0.13707998810585786\n",
      "epoch 93, loss 98.11849212646484\n",
      "16815 2278 0.13547427891763306\n",
      "epoch 94, loss 98.13504028320312\n",
      "16815 2296 0.13654475170978292\n",
      "epoch 95, loss 98.17171478271484\n",
      "16815 2279 0.13553374962830805\n",
      "epoch 96, loss 98.102294921875\n",
      "16815 2305 0.13707998810585786\n",
      "epoch 97, loss 98.0739974975586\n",
      "16815 2287 0.136009515313708\n",
      "epoch 98, loss 98.06024169921875\n",
      "16815 2285 0.135890573892358\n",
      "epoch 99, loss 98.0353012084961\n",
      "16815 2270 0.13499851323223314\n",
      "epoch 100, loss 98.0197982788086\n",
      "16815 2277 0.13541480820695806\n",
      "epoch 101, loss 98.06792449951172\n",
      "16815 2265 0.13470115967885815\n",
      "epoch 102, loss 98.01871490478516\n",
      "16815 2259 0.1343443354148082\n",
      "epoch 103, loss 97.97894287109375\n",
      "16815 2331 0.13862622658340767\n",
      "epoch 104, loss 97.92659759521484\n",
      "16815 2316 0.13773416592328278\n",
      "epoch 105, loss 97.97064971923828\n",
      "16815 2284 0.135831103181683\n",
      "epoch 106, loss 97.91861724853516\n",
      "16815 2300 0.1367826345524829\n",
      "epoch 107, loss 97.83621978759766\n",
      "16815 2336 0.13892358013678263\n",
      "epoch 108, loss 97.94801330566406\n",
      "16815 2307 0.13719892952720786\n",
      "epoch 109, loss 97.9499740600586\n",
      "16815 2340 0.1391614629794826\n",
      "epoch 110, loss 97.81945037841797\n",
      "16815 2315 0.13767469521260778\n",
      "epoch 111, loss 97.89933776855469\n",
      "16815 2311 0.13743681236990782\n",
      "epoch 112, loss 97.81722259521484\n",
      "16815 2352 0.13987511150758253\n",
      "epoch 113, loss 97.83152770996094\n",
      "16815 2313 0.1375557537912578\n",
      "epoch 114, loss 97.81580352783203\n",
      "16815 2288 0.136068986024383\n",
      "epoch 115, loss 97.80831909179688\n",
      "16815 2316 0.13773416592328278\n",
      "epoch 116, loss 97.76940155029297\n",
      "16815 2313 0.1375557537912578\n",
      "epoch 117, loss 97.79660034179688\n",
      "16815 2283 0.13577163247100804\n",
      "epoch 118, loss 97.75179290771484\n",
      "16815 2308 0.13725840023788285\n",
      "epoch 119, loss 97.82665252685547\n",
      "16815 2276 0.1353553374962831\n",
      "epoch 120, loss 97.71459197998047\n",
      "16815 2340 0.1391614629794826\n",
      "epoch 121, loss 97.73006439208984\n",
      "16815 2345 0.13945881653285758\n",
      "epoch 122, loss 97.73348999023438\n",
      "16815 2359 0.14029140648230745\n",
      "epoch 123, loss 97.72419738769531\n",
      "16815 2330 0.13856675587273268\n",
      "epoch 124, loss 97.66990661621094\n",
      "16815 2364 0.14058876003568244\n",
      "epoch 125, loss 97.68160247802734\n",
      "16815 2332 0.13868569729408267\n",
      "epoch 126, loss 97.67930603027344\n",
      "16815 2301 0.1368421052631579\n",
      "epoch 127, loss 97.61746978759766\n",
      "16815 2372 0.14106452572108236\n",
      "epoch 128, loss 97.70726013183594\n",
      "16815 2409 0.14326494201605708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 129, loss 97.54557800292969\n",
      "16815 2342 0.13928040440083259\n",
      "epoch 130, loss 97.68087005615234\n",
      "16815 2260 0.1344038061254832\n",
      "epoch 131, loss 97.68743133544922\n",
      "16815 2326 0.13832887303003272\n",
      "epoch 132, loss 97.57160949707031\n",
      "16815 2408 0.1432054713053821\n",
      "epoch 133, loss 97.56864166259766\n",
      "16815 2406 0.14308652988403212\n",
      "epoch 134, loss 97.57547760009766\n",
      "16815 2338 0.13904252155813263\n",
      "epoch 135, loss 97.49664306640625\n",
      "16815 2425 0.14421647338685697\n",
      "epoch 136, loss 97.4308853149414\n",
      "16815 2319 0.13791257805530777\n",
      "epoch 137, loss 97.47732543945312\n",
      "16815 2423 0.14409753196550698\n",
      "epoch 138, loss 97.46180725097656\n",
      "16815 2371 0.1410050550104074\n",
      "epoch 139, loss 97.33209991455078\n",
      "16815 2384 0.14177817424918226\n",
      "epoch 140, loss 97.62010955810547\n",
      "16815 2348 0.13963722866488254\n",
      "epoch 141, loss 97.33133697509766\n",
      "16815 2402 0.14284864704133216\n",
      "epoch 142, loss 97.51136779785156\n",
      "16815 2406 0.14308652988403212\n",
      "epoch 143, loss 97.4665298461914\n",
      "16815 2362 0.14046981861433244\n",
      "epoch 144, loss 97.52411651611328\n",
      "16815 2401 0.14278917633065716\n",
      "epoch 145, loss 97.61776733398438\n",
      "16815 2375 0.14124293785310735\n",
      "epoch 146, loss 97.34718322753906\n",
      "16815 2466 0.14665477252453166\n",
      "epoch 147, loss 97.4444580078125\n",
      "16815 2367 0.1407671721677074\n",
      "epoch 148, loss 97.48807525634766\n",
      "16815 2339 0.13910199226880762\n",
      "epoch 149, loss 97.47815704345703\n",
      "16815 2476 0.1472494796312816\n",
      "epoch 150, loss 97.42680358886719\n",
      "16815 2374 0.14118346714243235\n",
      "epoch 151, loss 97.37226104736328\n",
      "16815 2452 0.14582218257508178\n",
      "epoch 152, loss 97.47038269042969\n",
      "16815 2415 0.14362176628010706\n",
      "epoch 153, loss 97.51363372802734\n",
      "16815 2406 0.14308652988403212\n",
      "epoch 154, loss 97.097900390625\n",
      "16815 2510 0.14927148379423133\n",
      "epoch 155, loss 97.44822692871094\n",
      "16815 2389 0.14207552780255725\n",
      "epoch 156, loss 97.20005798339844\n",
      "16815 2364 0.14058876003568244\n",
      "epoch 157, loss 97.23768615722656\n",
      "16815 2475 0.1471900089206066\n",
      "epoch 158, loss 97.50936889648438\n",
      "16815 2386 0.14189711567053226\n",
      "epoch 159, loss 97.12223815917969\n",
      "16815 2477 0.1473089503419566\n",
      "epoch 160, loss 97.285888671875\n",
      "16815 2464 0.1465358311031817\n",
      "epoch 161, loss 97.38993835449219\n",
      "16815 2357 0.14017246506095749\n",
      "epoch 162, loss 96.92915344238281\n",
      "16815 2558 0.152126077906631\n",
      "epoch 163, loss 97.42839050292969\n",
      "16815 2412 0.14344335414808207\n",
      "epoch 164, loss 97.12356567382812\n",
      "16815 2414 0.14356229556943206\n",
      "epoch 165, loss 97.38141632080078\n",
      "16815 2394 0.1423728813559322\n",
      "epoch 166, loss 97.01183319091797\n",
      "16815 2434 0.1447517097829319\n",
      "epoch 167, loss 97.18254089355469\n",
      "16815 2409 0.14326494201605708\n",
      "epoch 168, loss 97.0904541015625\n",
      "16815 2469 0.14683318465655665\n",
      "epoch 169, loss 97.30145263671875\n",
      "16815 2423 0.14409753196550698\n",
      "epoch 170, loss 96.97013854980469\n",
      "16815 2602 0.15474278917633066\n",
      "epoch 171, loss 96.89876556396484\n",
      "16815 2498 0.14855783526613142\n",
      "epoch 172, loss 97.0237045288086\n",
      "16815 2556 0.152007136485281\n",
      "epoch 173, loss 97.25627899169922\n",
      "16815 2462 0.1464168896818317\n",
      "epoch 174, loss 96.90351867675781\n",
      "16815 2557 0.152066607195956\n",
      "epoch 175, loss 97.26864624023438\n",
      "16815 2381 0.1415997621171573\n",
      "epoch 176, loss 97.2437515258789\n",
      "16815 2392 0.1422539399345822\n",
      "epoch 177, loss 96.8780288696289\n",
      "16815 2563 0.15242343146000595\n",
      "epoch 178, loss 96.92256927490234\n",
      "16815 2543 0.1512340172465061\n",
      "epoch 179, loss 96.71026611328125\n",
      "16815 2614 0.15545643770443057\n",
      "epoch 180, loss 97.09030151367188\n",
      "16815 2435 0.1448111804936069\n",
      "epoch 181, loss 97.0876693725586\n",
      "16815 2495 0.14837942313410646\n",
      "epoch 182, loss 96.75070190429688\n",
      "16815 2629 0.15634849836455544\n",
      "epoch 183, loss 97.04316711425781\n",
      "16815 2571 0.1528991971454059\n",
      "epoch 184, loss 96.92301940917969\n",
      "16815 2467 0.14671424323520665\n",
      "epoch 185, loss 96.98735809326172\n",
      "16815 2527 0.15028248587570622\n",
      "epoch 186, loss 96.69564819335938\n",
      "16815 2567 0.1526613143027059\n",
      "epoch 187, loss 96.9404067993164\n",
      "16815 2574 0.15307760927743086\n",
      "epoch 188, loss 96.91474914550781\n",
      "16815 2477 0.1473089503419566\n",
      "epoch 189, loss 96.58355712890625\n",
      "16815 2586 0.15379125780553077\n",
      "epoch 190, loss 96.64269256591797\n",
      "16815 2616 0.15557537912578057\n",
      "epoch 191, loss 96.81513977050781\n",
      "16815 2598 0.15450490633363068\n",
      "epoch 192, loss 96.8226547241211\n",
      "16815 2644 0.15724055902468034\n",
      "epoch 193, loss 96.78361511230469\n",
      "16815 2516 0.14962830805828128\n",
      "epoch 194, loss 96.68865966796875\n",
      "16815 2615 0.15551590841510557\n",
      "epoch 195, loss 96.98407745361328\n",
      "16815 2541 0.1511150758251561\n",
      "epoch 196, loss 96.67568969726562\n",
      "16815 2549 0.15159084151055605\n",
      "epoch 197, loss 96.53277587890625\n",
      "16815 2607 0.15504014272970562\n",
      "epoch 198, loss 96.93633270263672\n",
      "16815 2427 0.14433541480820697\n",
      "epoch 199, loss 97.03397369384766\n",
      "16815 2495 0.14837942313410646\n",
      "epoch 200, loss 96.78143310546875\n",
      "16815 2570 0.1528397264347309\n",
      "epoch 201, loss 96.90754699707031\n",
      "16815 2442 0.14522747546833184\n",
      "epoch 202, loss 96.55059814453125\n",
      "16815 2508 0.14915254237288136\n",
      "epoch 203, loss 96.55548095703125\n",
      "16815 2451 0.14576271186440679\n",
      "epoch 204, loss 96.20597076416016\n",
      "16815 2629 0.15634849836455544\n",
      "epoch 205, loss 96.7616958618164\n",
      "16815 2443 0.14528694617900684\n",
      "epoch 206, loss 96.65042877197266\n",
      "16815 2517 0.14968777876895628\n",
      "epoch 207, loss 96.86058807373047\n",
      "16815 2404 0.14296758846268212\n",
      "epoch 208, loss 96.36884307861328\n",
      "16815 2594 0.15426702349093072\n",
      "epoch 209, loss 96.65780639648438\n",
      "16815 2478 0.14736842105263157\n",
      "epoch 210, loss 96.88052368164062\n",
      "16815 2483 0.14766577460600655\n",
      "epoch 211, loss 96.31010437011719\n",
      "16815 2515 0.14956883734760631\n",
      "epoch 212, loss 96.73039245605469\n",
      "16815 2423 0.14409753196550698\n",
      "epoch 213, loss 96.70431518554688\n",
      "16815 2526 0.15022301516503123\n",
      "epoch 214, loss 96.3093032836914\n",
      "16815 2605 0.15492120130835563\n",
      "epoch 215, loss 96.67948150634766\n",
      "16815 2514 0.14950936663693132\n",
      "epoch 216, loss 96.5019760131836\n",
      "16815 2504 0.14891465953018138\n",
      "epoch 217, loss 96.23662567138672\n",
      "16815 2573 0.15301813856675586\n",
      "epoch 218, loss 96.43089294433594\n",
      "16815 2499 0.14861730597680642\n",
      "epoch 219, loss 96.19712829589844\n",
      "16815 2607 0.15504014272970562\n",
      "epoch 220, loss 96.34857177734375\n",
      "16815 2592 0.15414808206958072\n",
      "epoch 221, loss 96.64116668701172\n",
      "16815 2595 0.1543264942016057\n",
      "epoch 222, loss 96.64456176757812\n",
      "16815 2509 0.14921201308355636\n",
      "epoch 223, loss 96.298583984375\n",
      "16815 2581 0.1534939042521558\n",
      "epoch 224, loss 96.28990173339844\n",
      "16815 2602 0.15474278917633066\n",
      "epoch 225, loss 96.29141235351562\n",
      "16815 2654 0.15783526613143026\n",
      "epoch 226, loss 96.39718627929688\n",
      "16815 2501 0.1487362473981564\n",
      "epoch 227, loss 96.35031127929688\n",
      "16815 2571 0.1528991971454059\n",
      "epoch 228, loss 96.223876953125\n",
      "16815 2605 0.15492120130835563\n",
      "epoch 229, loss 96.66455841064453\n",
      "16815 2539 0.15099613440380613\n",
      "epoch 230, loss 96.1450424194336\n",
      "16815 2650 0.1575973832887303\n",
      "epoch 231, loss 96.49946594238281\n",
      "16815 2598 0.15450490633363068\n",
      "epoch 232, loss 96.323974609375\n",
      "16815 2529 0.1504014272970562\n",
      "epoch 233, loss 96.16096496582031\n",
      "16815 2562 0.15236396074933095\n",
      "epoch 234, loss 96.20478057861328\n",
      "16815 2556 0.152007136485281\n",
      "epoch 235, loss 96.45858001708984\n",
      "16815 2565 0.15254237288135594\n",
      "epoch 236, loss 96.12506103515625\n",
      "16815 2592 0.15414808206958072\n",
      "epoch 237, loss 96.24636840820312\n",
      "16815 2618 0.15569432054713053\n",
      "epoch 238, loss 96.28296661376953\n",
      "16815 2551 0.15170978293190604\n",
      "epoch 239, loss 95.896240234375\n",
      "16815 2706 0.16092774308652988\n",
      "epoch 240, loss 96.2581558227539\n",
      "16815 2587 0.15385072851620576\n",
      "epoch 241, loss 96.69901275634766\n",
      "16815 2557 0.152066607195956\n",
      "epoch 242, loss 95.77484893798828\n",
      "16815 2698 0.16045197740112993\n",
      "epoch 243, loss 96.66290283203125\n",
      "16815 2566 0.1526018435920309\n",
      "epoch 244, loss 96.06965637207031\n",
      "16815 2609 0.15515908415105562\n",
      "epoch 245, loss 96.28492736816406\n",
      "16815 2549 0.15159084151055605\n",
      "epoch 246, loss 96.50982666015625\n",
      "16815 2533 0.15063931013975618\n",
      "epoch 247, loss 95.69804382324219\n",
      "16815 2628 0.15628902765388047\n",
      "epoch 248, loss 96.4476318359375\n",
      "16815 2439 0.14504906333630688\n",
      "epoch 249, loss 96.12422943115234\n",
      "16815 2579 0.15337496283080582\n",
      "epoch 250, loss 95.9850082397461\n",
      "16815 2534 0.15069878085043117\n",
      "epoch 251, loss 96.52175903320312\n",
      "16815 2453 0.14588165328575675\n",
      "epoch 252, loss 96.01825714111328\n",
      "16815 2563 0.15242343146000595\n",
      "epoch 253, loss 96.12664031982422\n",
      "16815 2597 0.1544454356229557\n",
      "epoch 254, loss 96.31034851074219\n",
      "16815 2546 0.15141242937853108\n",
      "epoch 255, loss 96.07572937011719\n",
      "16815 2629 0.15634849836455544\n",
      "epoch 256, loss 96.18767547607422\n",
      "16815 2510 0.14927148379423133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 257, loss 95.77066040039062\n",
      "16815 2585 0.15373178709485577\n",
      "epoch 258, loss 96.31267547607422\n",
      "16815 2546 0.15141242937853108\n",
      "epoch 259, loss 95.83330535888672\n",
      "16815 2607 0.15504014272970562\n",
      "epoch 260, loss 95.93801879882812\n",
      "16815 2616 0.15557537912578057\n",
      "epoch 261, loss 96.24617004394531\n",
      "16815 2508 0.14915254237288136\n",
      "epoch 262, loss 95.79678344726562\n",
      "16815 2559 0.152185548617306\n",
      "epoch 263, loss 96.299560546875\n",
      "16815 2517 0.14968777876895628\n",
      "epoch 264, loss 96.74430847167969\n",
      "16815 2465 0.1465953018138567\n",
      "epoch 265, loss 95.98558807373047\n",
      "16815 2606 0.15498067201903062\n",
      "epoch 266, loss 95.90461730957031\n",
      "16815 2561 0.15230449003865595\n",
      "epoch 267, loss 96.30904388427734\n",
      "16815 2505 0.14897413024085637\n",
      "epoch 268, loss 96.0811538696289\n",
      "16815 2561 0.15230449003865595\n",
      "epoch 269, loss 95.99610137939453\n",
      "16815 2545 0.15135295866785609\n",
      "epoch 270, loss 96.09835052490234\n",
      "16815 2561 0.15230449003865595\n",
      "epoch 271, loss 95.98102569580078\n",
      "16815 2530 0.1504608980077312\n",
      "epoch 272, loss 96.43232727050781\n",
      "16815 2527 0.15028248587570622\n",
      "epoch 273, loss 96.01548767089844\n",
      "16815 2650 0.1575973832887303\n",
      "epoch 274, loss 96.27239990234375\n",
      "16815 2562 0.15236396074933095\n",
      "epoch 275, loss 95.88589477539062\n",
      "16815 2558 0.152126077906631\n",
      "epoch 276, loss 95.80709838867188\n",
      "16815 2614 0.15545643770443057\n",
      "epoch 277, loss 96.15624237060547\n",
      "16815 2531 0.15052036871840618\n",
      "epoch 278, loss 96.14549255371094\n",
      "16815 2606 0.15498067201903062\n",
      "epoch 279, loss 96.1666030883789\n",
      "16815 2587 0.15385072851620576\n",
      "epoch 280, loss 96.11012268066406\n",
      "16815 2561 0.15230449003865595\n",
      "epoch 281, loss 95.34439849853516\n",
      "16815 2682 0.15950044603033006\n",
      "epoch 282, loss 96.37604522705078\n",
      "16815 2510 0.14927148379423133\n",
      "epoch 283, loss 96.01900482177734\n",
      "16815 2503 0.1488551888195064\n",
      "epoch 284, loss 95.99027252197266\n",
      "16815 2547 0.15147190008920608\n",
      "epoch 285, loss 95.90631103515625\n",
      "16815 2606 0.15498067201903062\n",
      "epoch 286, loss 96.2850341796875\n",
      "16815 2569 0.1527802557240559\n",
      "epoch 287, loss 96.13749694824219\n",
      "16815 2607 0.15504014272970562\n",
      "epoch 288, loss 95.92028045654297\n",
      "16815 2586 0.15379125780553077\n",
      "epoch 289, loss 95.66207122802734\n",
      "16815 2566 0.1526018435920309\n",
      "epoch 290, loss 96.16596221923828\n",
      "16815 2496 0.14843889384478146\n",
      "epoch 291, loss 96.36595153808594\n",
      "16815 2521 0.14992566161165627\n",
      "epoch 292, loss 95.66118621826172\n",
      "16815 2523 0.15004460303300624\n",
      "epoch 293, loss 95.89019012451172\n",
      "16815 2546 0.15141242937853108\n",
      "epoch 294, loss 96.60791015625\n",
      "16815 2513 0.14944989592625632\n",
      "epoch 295, loss 95.45539855957031\n",
      "16815 2685 0.15967885816235505\n",
      "epoch 296, loss 95.86988067626953\n",
      "16815 2554 0.151888195063931\n",
      "epoch 297, loss 96.4192886352539\n",
      "16815 2586 0.15379125780553077\n",
      "epoch 298, loss 96.04229736328125\n",
      "16815 2514 0.14950936663693132\n",
      "epoch 299, loss 96.02100372314453\n",
      "16815 2505 0.14897413024085637\n",
      "epoch 300, loss 96.31784057617188\n",
      "16815 2474 0.1471305382099316\n",
      "epoch 301, loss 95.97543334960938\n",
      "16815 2506 0.14903360095153137\n",
      "epoch 302, loss 96.31336975097656\n",
      "16815 2591 0.15408861135890575\n",
      "epoch 303, loss 95.96015167236328\n",
      "16815 2583 0.1536128456735058\n",
      "epoch 304, loss 96.48454284667969\n",
      "16815 2597 0.1544454356229557\n",
      "epoch 305, loss 95.97659301757812\n",
      "16815 2594 0.15426702349093072\n",
      "epoch 306, loss 96.1297378540039\n",
      "16815 2547 0.15147190008920608\n",
      "epoch 307, loss 95.89517974853516\n",
      "16815 2542 0.1511745465358311\n",
      "epoch 308, loss 95.81073760986328\n",
      "16815 2610 0.15521855486173058\n",
      "epoch 309, loss 95.68773651123047\n",
      "16815 2687 0.15979779958370502\n",
      "epoch 310, loss 96.70964050292969\n",
      "16815 2522 0.14998513232233124\n",
      "epoch 311, loss 95.80149841308594\n",
      "16815 2643 0.15718108831400535\n",
      "epoch 312, loss 96.03744506835938\n",
      "16815 2543 0.1512340172465061\n",
      "epoch 313, loss 95.89960479736328\n",
      "16815 2581 0.1534939042521558\n",
      "epoch 314, loss 96.11166381835938\n",
      "16815 2506 0.14903360095153137\n",
      "epoch 315, loss 96.29545593261719\n",
      "16815 2510 0.14927148379423133\n",
      "epoch 316, loss 95.45161437988281\n",
      "16815 2582 0.1535533749628308\n",
      "epoch 317, loss 96.46427154541016\n",
      "16815 2543 0.1512340172465061\n",
      "epoch 318, loss 96.12454986572266\n",
      "16815 2620 0.15581326196848053\n",
      "epoch 319, loss 96.28446960449219\n",
      "16815 2585 0.15373178709485577\n",
      "epoch 320, loss 95.86900329589844\n",
      "16815 2565 0.15254237288135594\n",
      "epoch 321, loss 95.6163330078125\n",
      "16815 2684 0.15961938745168006\n",
      "epoch 322, loss 96.43416595458984\n",
      "16815 2516 0.14962830805828128\n",
      "epoch 323, loss 96.19822692871094\n",
      "16815 2609 0.15515908415105562\n",
      "epoch 324, loss 95.51691436767578\n",
      "16815 2639 0.15694320547130539\n",
      "epoch 325, loss 96.54252624511719\n",
      "16815 2484 0.14772524531668155\n",
      "epoch 326, loss 95.84799194335938\n",
      "16815 2601 0.15468331846565567\n",
      "epoch 327, loss 95.81444549560547\n",
      "16815 2643 0.15718108831400535\n",
      "epoch 328, loss 95.84846496582031\n",
      "16815 2524 0.15010407374368123\n",
      "epoch 329, loss 95.57394409179688\n",
      "16815 2589 0.15396966993755576\n",
      "epoch 330, loss 96.39474487304688\n",
      "16815 2507 0.14909307166220637\n",
      "epoch 331, loss 95.54212951660156\n",
      "16815 2578 0.15331549212013085\n",
      "epoch 332, loss 96.03286743164062\n",
      "16815 2506 0.14903360095153137\n",
      "epoch 333, loss 96.54379272460938\n",
      "16815 2573 0.15301813856675586\n",
      "epoch 334, loss 95.65971374511719\n",
      "16815 2677 0.1592030924769551\n",
      "epoch 335, loss 95.84871673583984\n",
      "16815 2489 0.1480225988700565\n",
      "epoch 336, loss 96.44612121582031\n",
      "16815 2527 0.15028248587570622\n",
      "epoch 337, loss 95.47341918945312\n",
      "16815 2595 0.1543264942016057\n",
      "epoch 338, loss 95.90802764892578\n",
      "16815 2482 0.14760630389533155\n",
      "epoch 339, loss 95.59547424316406\n",
      "16815 2515 0.14956883734760631\n",
      "epoch 340, loss 96.00337982177734\n",
      "16815 2625 0.15611061552185548\n",
      "epoch 341, loss 95.95562744140625\n",
      "16815 2544 0.1512934879571811\n",
      "epoch 342, loss 96.27326202392578\n",
      "16815 2526 0.15022301516503123\n",
      "epoch 343, loss 95.8667221069336\n",
      "16815 2566 0.1526018435920309\n",
      "epoch 344, loss 96.04288482666016\n",
      "16815 2626 0.15617008623253048\n",
      "epoch 345, loss 95.8987808227539\n",
      "16815 2588 0.15391019922688076\n",
      "epoch 346, loss 96.62801361083984\n",
      "16815 2516 0.14962830805828128\n",
      "epoch 347, loss 95.88825225830078\n",
      "16815 2578 0.15331549212013085\n",
      "epoch 348, loss 96.28874206542969\n",
      "16815 2441 0.14516800475765684\n",
      "epoch 349, loss 95.5699691772461\n",
      "16815 2508 0.14915254237288136\n",
      "epoch 350, loss 96.07032012939453\n",
      "16815 2554 0.151888195063931\n",
      "epoch 351, loss 96.00206756591797\n",
      "16815 2461 0.1463574189711567\n",
      "epoch 352, loss 95.94083404541016\n",
      "16815 2539 0.15099613440380613\n",
      "epoch 353, loss 96.56452178955078\n",
      "16815 2464 0.1465358311031817\n",
      "epoch 354, loss 95.88265991210938\n",
      "16815 2638 0.1568837347606304\n",
      "epoch 355, loss 95.732421875\n",
      "16815 2540 0.15105560511448113\n",
      "epoch 356, loss 96.44631958007812\n",
      "16815 2674 0.1590246803449301\n",
      "epoch 357, loss 95.91915130615234\n",
      "16815 2554 0.151888195063931\n",
      "epoch 358, loss 96.03904724121094\n",
      "16815 2594 0.15426702349093072\n",
      "epoch 359, loss 96.8633804321289\n",
      "16815 2489 0.1480225988700565\n",
      "epoch 360, loss 96.1043701171875\n",
      "16815 2514 0.14950936663693132\n",
      "epoch 361, loss 95.67701721191406\n",
      "16815 2558 0.152126077906631\n",
      "epoch 362, loss 96.06314086914062\n",
      "16815 2524 0.15010407374368123\n",
      "epoch 363, loss 95.4287109375\n",
      "16815 2558 0.152126077906631\n",
      "epoch 364, loss 95.64160919189453\n",
      "16815 2510 0.14927148379423133\n",
      "epoch 365, loss 96.39973449707031\n",
      "16815 2487 0.1479036574487065\n",
      "epoch 366, loss 96.32398986816406\n",
      "16815 2444 0.14534641688968183\n",
      "epoch 367, loss 95.92943572998047\n",
      "16815 2573 0.15301813856675586\n",
      "epoch 368, loss 95.57422637939453\n",
      "16815 2594 0.15426702349093072\n",
      "epoch 369, loss 95.82722473144531\n",
      "16815 2489 0.1480225988700565\n",
      "epoch 370, loss 94.9162826538086\n",
      "16815 2659 0.15813261968480524\n",
      "epoch 371, loss 97.90247344970703\n",
      "16815 2418 0.14380017841213202\n",
      "epoch 372, loss 96.1537857055664\n",
      "16815 2550 0.15165031222123104\n",
      "epoch 373, loss 95.42056274414062\n",
      "16815 2750 0.16354445435622955\n",
      "epoch 374, loss 96.2980728149414\n",
      "16815 2568 0.1527207850133809\n",
      "epoch 375, loss 96.60115051269531\n",
      "16815 2566 0.1526018435920309\n",
      "epoch 376, loss 96.05009460449219\n",
      "16815 2595 0.1543264942016057\n",
      "epoch 377, loss 95.43077087402344\n",
      "16815 2738 0.16283080582812964\n",
      "epoch 378, loss 95.82782745361328\n",
      "16815 2508 0.14915254237288136\n",
      "epoch 379, loss 96.13933563232422\n",
      "16815 2458 0.14617900683913174\n",
      "epoch 380, loss 96.3113021850586\n",
      "16815 2507 0.14909307166220637\n",
      "epoch 381, loss 95.5722885131836\n",
      "16815 2598 0.15450490633363068\n",
      "epoch 382, loss 95.24901580810547\n",
      "16815 2606 0.15498067201903062\n",
      "epoch 383, loss 96.61824798583984\n",
      "16815 2471 0.14695212607790664\n",
      "epoch 384, loss 96.54854583740234\n",
      "16815 2549 0.15159084151055605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 385, loss 96.43907928466797\n",
      "16815 2538 0.15093666369313113\n",
      "epoch 386, loss 95.2856674194336\n",
      "16815 2842 0.16901575973832889\n",
      "epoch 387, loss 96.6275634765625\n",
      "16815 2451 0.14576271186440679\n",
      "epoch 388, loss 95.37239074707031\n",
      "16815 2616 0.15557537912578057\n",
      "epoch 389, loss 96.47876739501953\n",
      "16815 2449 0.1456437704430568\n",
      "epoch 390, loss 95.36764526367188\n",
      "16815 2661 0.1582515611061552\n",
      "epoch 391, loss 96.3208236694336\n",
      "16815 2511 0.14933095450490633\n",
      "epoch 392, loss 96.65312957763672\n",
      "16815 2540 0.15105560511448113\n",
      "epoch 393, loss 96.18526458740234\n",
      "16815 2583 0.1536128456735058\n",
      "epoch 394, loss 95.85448455810547\n",
      "16815 2612 0.15533749628308058\n",
      "epoch 395, loss 95.42078399658203\n",
      "16815 2551 0.15170978293190604\n",
      "epoch 396, loss 96.26543426513672\n",
      "16815 2520 0.14986619090098127\n",
      "epoch 397, loss 95.96440124511719\n",
      "16815 2547 0.15147190008920608\n",
      "epoch 398, loss 95.7623291015625\n",
      "16815 2616 0.15557537912578057\n",
      "epoch 399, loss 96.8863525390625\n",
      "16815 2432 0.14463276836158193\n",
      "epoch 400, loss 96.2594985961914\n",
      "16815 2475 0.1471900089206066\n",
      "epoch 401, loss 95.74458312988281\n",
      "16815 2591 0.15408861135890575\n",
      "epoch 402, loss 95.77803802490234\n",
      "16815 2586 0.15379125780553077\n",
      "epoch 403, loss 96.41666412353516\n",
      "16815 2493 0.14826048171275646\n",
      "epoch 404, loss 96.25581359863281\n",
      "16815 2566 0.1526018435920309\n",
      "epoch 405, loss 96.43687438964844\n",
      "16815 2567 0.1526613143027059\n",
      "epoch 406, loss 96.70574951171875\n",
      "16815 2446 0.14546535831103183\n",
      "epoch 407, loss 95.59329223632812\n",
      "16815 2801 0.16657746060065418\n",
      "epoch 408, loss 95.88124084472656\n",
      "16815 2637 0.1568242640499554\n",
      "epoch 409, loss 97.24339294433594\n",
      "16815 2397 0.14255129348795717\n",
      "epoch 410, loss 95.60590362548828\n",
      "16815 2764 0.16437704430567945\n",
      "epoch 411, loss 96.33277893066406\n",
      "16815 2573 0.15301813856675586\n",
      "epoch 412, loss 95.88996124267578\n",
      "16815 2513 0.14944989592625632\n",
      "epoch 413, loss 95.52131652832031\n",
      "16815 2640 0.15700267618198038\n",
      "epoch 414, loss 95.70714569091797\n",
      "16815 2591 0.15408861135890575\n",
      "epoch 415, loss 96.24444580078125\n",
      "16815 2448 0.1455842997323818\n",
      "epoch 416, loss 96.33916473388672\n",
      "16815 2499 0.14861730597680642\n",
      "epoch 417, loss 96.67826080322266\n",
      "16815 2401 0.14278917633065716\n",
      "epoch 418, loss 95.4001235961914\n",
      "16815 2612 0.15533749628308058\n",
      "epoch 419, loss 95.86299133300781\n",
      "16815 2510 0.14927148379423133\n",
      "epoch 420, loss 96.45911407470703\n",
      "16815 2470 0.14689265536723164\n",
      "epoch 421, loss 95.42112731933594\n",
      "16815 2612 0.15533749628308058\n",
      "epoch 422, loss 97.04997253417969\n",
      "16815 2466 0.14665477252453166\n",
      "epoch 423, loss 96.72266387939453\n",
      "16815 2419 0.14385964912280702\n",
      "epoch 424, loss 96.06311798095703\n",
      "16815 2564 0.15248290217068095\n",
      "epoch 425, loss 95.90184783935547\n",
      "16815 2887 0.17169194171870353\n",
      "epoch 426, loss 97.896240234375\n",
      "16815 2296 0.13654475170978292\n",
      "epoch 427, loss 96.22869873046875\n",
      "16815 2630 0.15640796907523044\n",
      "epoch 428, loss 95.20364379882812\n",
      "16815 2942 0.17496283080582814\n",
      "epoch 429, loss 95.4266357421875\n",
      "16815 2550 0.15165031222123104\n",
      "epoch 430, loss 95.47040557861328\n",
      "16815 2603 0.15480225988700566\n",
      "epoch 431, loss 95.67485809326172\n",
      "16815 2487 0.1479036574487065\n",
      "epoch 432, loss 96.4245834350586\n",
      "16815 2421 0.14397859054415701\n",
      "epoch 433, loss 95.74642944335938\n",
      "16815 2651 0.1576568539994053\n",
      "epoch 434, loss 96.17289733886719\n",
      "16815 2478 0.14736842105263157\n",
      "epoch 435, loss 96.05708312988281\n",
      "16815 2706 0.16092774308652988\n",
      "epoch 436, loss 95.0768051147461\n",
      "16815 2690 0.15997621171573\n",
      "epoch 437, loss 97.54818725585938\n",
      "16815 2375 0.14124293785310735\n",
      "epoch 438, loss 96.33268737792969\n",
      "16815 2506 0.14903360095153137\n",
      "epoch 439, loss 95.01603698730469\n",
      "16815 2907 0.17288135593220338\n",
      "epoch 440, loss 96.03545379638672\n",
      "16815 2632 0.15652691049658043\n",
      "epoch 441, loss 96.1419677734375\n",
      "16815 2475 0.1471900089206066\n",
      "epoch 442, loss 95.11089324951172\n",
      "16815 2668 0.15866785608088016\n",
      "epoch 443, loss 96.28650665283203\n",
      "16815 2519 0.14980672019030628\n",
      "epoch 444, loss 95.65243530273438\n",
      "16815 2568 0.1527207850133809\n",
      "epoch 445, loss 96.54460906982422\n",
      "16815 2436 0.1448706512042819\n",
      "epoch 446, loss 96.74083709716797\n",
      "16815 2535 0.15075825156110614\n",
      "epoch 447, loss 96.62000274658203\n",
      "16815 2470 0.14689265536723164\n",
      "epoch 448, loss 96.14871978759766\n",
      "16815 2480 0.14748736247398156\n",
      "epoch 449, loss 94.70394897460938\n",
      "16815 2835 0.16859946476360393\n",
      "epoch 450, loss 97.17249298095703\n",
      "16815 2431 0.14457329765090693\n",
      "epoch 451, loss 95.19497680664062\n",
      "16815 2715 0.16146297948260482\n",
      "epoch 452, loss 95.48513793945312\n",
      "16815 2637 0.1568242640499554\n",
      "epoch 453, loss 96.88224792480469\n",
      "16815 2456 0.14606006541778174\n",
      "epoch 454, loss 95.61418151855469\n",
      "16815 2670 0.15878679750223015\n",
      "epoch 455, loss 95.11164855957031\n",
      "16815 2561 0.15230449003865595\n",
      "epoch 456, loss 95.95142364501953\n",
      "16815 2596 0.1543859649122807\n",
      "epoch 457, loss 95.80731201171875\n",
      "16815 2485 0.14778471602735652\n",
      "epoch 458, loss 96.0978012084961\n",
      "16815 2531 0.15052036871840618\n",
      "epoch 459, loss 95.01425170898438\n",
      "16815 2736 0.16271186440677965\n",
      "epoch 460, loss 99.0594711303711\n",
      "16815 2286 0.135950044603033\n",
      "epoch 461, loss 96.892578125\n",
      "16815 2415 0.14362176628010706\n",
      "epoch 462, loss 96.59121704101562\n",
      "16815 2481 0.14754683318465656\n",
      "epoch 463, loss 96.40764617919922\n",
      "16815 2490 0.1480820695807315\n",
      "epoch 464, loss 96.13101196289062\n",
      "16815 2525 0.15016354445435623\n",
      "epoch 465, loss 95.93334197998047\n",
      "16815 2533 0.15063931013975618\n",
      "epoch 466, loss 95.58893585205078\n",
      "16815 2534 0.15069878085043117\n",
      "epoch 467, loss 95.04584503173828\n",
      "16815 2753 0.16372286648825454\n",
      "epoch 468, loss 94.10564422607422\n",
      "16815 3023 0.17977995837050254\n",
      "epoch 469, loss 96.4859848022461\n",
      "16815 2613 0.15539696699375558\n",
      "epoch 470, loss 96.10382843017578\n",
      "16815 2738 0.16283080582812964\n",
      "epoch 471, loss 94.32054138183594\n",
      "16815 2854 0.1697294082664288\n",
      "epoch 472, loss 99.33794403076172\n",
      "16815 2300 0.1367826345524829\n",
      "epoch 473, loss 96.29708862304688\n",
      "16815 2506 0.14903360095153137\n",
      "epoch 474, loss 95.03783416748047\n",
      "16815 3000 0.1784121320249777\n",
      "epoch 475, loss 95.03762817382812\n",
      "16815 2765 0.16443651501635445\n",
      "epoch 476, loss 98.8968276977539\n",
      "16815 2426 0.14427594409753197\n",
      "epoch 477, loss 97.29560852050781\n",
      "16815 2418 0.14380017841213202\n",
      "epoch 478, loss 96.79772186279297\n",
      "16815 2431 0.14457329765090693\n",
      "epoch 479, loss 96.34420776367188\n",
      "16815 2459 0.14623847754980673\n",
      "epoch 480, loss 95.90656280517578\n",
      "16815 2623 0.1559916741005055\n",
      "epoch 481, loss 95.35436248779297\n",
      "16815 2673 0.15896520963425512\n",
      "epoch 482, loss 94.01502227783203\n",
      "16815 3228 0.191971454058876\n",
      "epoch 483, loss 94.62615966796875\n",
      "16815 2777 0.16515016354445436\n",
      "epoch 484, loss 99.56076049804688\n",
      "16815 2346 0.13951828724353257\n",
      "epoch 485, loss 96.60448455810547\n",
      "16815 2411 0.14338388343740707\n",
      "epoch 486, loss 95.52305603027344\n",
      "16815 2894 0.17210823669342848\n",
      "epoch 487, loss 94.06991577148438\n",
      "16815 3133 0.1863217365447517\n",
      "epoch 488, loss 94.88274383544922\n",
      "16815 2652 0.1577163247100803\n",
      "epoch 489, loss 96.75045776367188\n",
      "16815 2565 0.15254237288135594\n",
      "epoch 490, loss 95.44491577148438\n",
      "16815 2667 0.15860838537020516\n",
      "epoch 491, loss 95.12379455566406\n",
      "16815 2605 0.15492120130835563\n",
      "epoch 492, loss 98.43727111816406\n",
      "16815 2370 0.1409455842997324\n",
      "epoch 493, loss 96.8258056640625\n",
      "16815 2414 0.14356229556943206\n",
      "epoch 494, loss 96.16223907470703\n",
      "16815 2636 0.1567647933392804\n",
      "epoch 495, loss 94.6797866821289\n",
      "16815 3003 0.17859054415700268\n",
      "epoch 496, loss 95.86714935302734\n",
      "16815 2699 0.16051144811180493\n",
      "epoch 497, loss 96.66207122802734\n",
      "16815 2515 0.14956883734760631\n",
      "epoch 498, loss 96.28466796875\n",
      "16815 2659 0.15813261968480524\n",
      "epoch 499, loss 96.59063720703125\n",
      "16815 2482 0.14760630389533155\n",
      "epoch 500, loss 95.85668182373047\n",
      "16815 2744 0.1631876300921796\n",
      "epoch 501, loss 95.35366821289062\n",
      "16815 2663 0.1583705025275052\n",
      "epoch 502, loss 95.52921295166016\n",
      "16815 2578 0.15331549212013085\n",
      "epoch 503, loss 95.5575942993164\n",
      "16815 2624 0.1560511448111805\n",
      "epoch 504, loss 95.35420989990234\n",
      "16815 2547 0.15147190008920608\n",
      "epoch 505, loss 96.27457427978516\n",
      "16815 2527 0.15028248587570622\n",
      "epoch 506, loss 95.85509490966797\n",
      "16815 2616 0.15557537912578057\n",
      "epoch 507, loss 95.75048828125\n",
      "16815 2649 0.1575379125780553\n",
      "epoch 508, loss 97.78572082519531\n",
      "16815 2326 0.13832887303003272\n",
      "epoch 509, loss 96.8629379272461\n",
      "16815 2415 0.14362176628010706\n",
      "epoch 510, loss 96.50547790527344\n",
      "16815 2436 0.1448706512042819\n",
      "epoch 511, loss 96.0388412475586\n",
      "16815 2462 0.1464168896818317\n",
      "epoch 512, loss 95.51524353027344\n",
      "16815 2641 0.15706214689265538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 513, loss 95.84346008300781\n",
      "16815 2822 0.16782634552482903\n",
      "epoch 514, loss 94.84681701660156\n",
      "16815 2772 0.1648528099910794\n",
      "epoch 515, loss 98.59579467773438\n",
      "16815 2313 0.1375557537912578\n",
      "epoch 516, loss 96.31900787353516\n",
      "16815 2472 0.1470115967885816\n",
      "epoch 517, loss 95.54879760742188\n",
      "16815 2711 0.16122509663990484\n",
      "epoch 518, loss 94.1701889038086\n",
      "16815 3041 0.1808504311626524\n",
      "epoch 519, loss 94.90072631835938\n",
      "16815 2623 0.1559916741005055\n",
      "epoch 520, loss 97.30561065673828\n",
      "16815 2452 0.14582218257508178\n",
      "epoch 521, loss 94.75459289550781\n",
      "16815 2835 0.16859946476360393\n",
      "epoch 522, loss 96.66429901123047\n",
      "16815 2476 0.1472494796312816\n",
      "epoch 523, loss 96.02755737304688\n",
      "16815 2803 0.16669640202200417\n",
      "epoch 524, loss 95.6021957397461\n",
      "16815 2626 0.15617008623253048\n",
      "epoch 525, loss 95.93180847167969\n",
      "16815 2558 0.152126077906631\n",
      "epoch 526, loss 95.06046295166016\n",
      "16815 2739 0.16289027653880464\n",
      "epoch 527, loss 98.16374206542969\n",
      "16815 2324 0.13820993160868272\n",
      "epoch 528, loss 96.01087951660156\n",
      "16815 2553 0.15182872435325603\n",
      "epoch 529, loss 95.69300079345703\n",
      "16815 2853 0.1696699375557538\n",
      "epoch 530, loss 96.14832305908203\n",
      "16815 2500 0.14867677668748142\n",
      "epoch 531, loss 94.61927032470703\n",
      "16815 2730 0.1623550401427297\n",
      "epoch 532, loss 95.80693054199219\n",
      "16815 2525 0.15016354445435623\n",
      "epoch 533, loss 95.17794036865234\n",
      "16815 2597 0.1544454356229557\n",
      "epoch 534, loss 97.10704040527344\n",
      "16815 2445 0.14540588760035683\n",
      "epoch 535, loss 95.37897491455078\n",
      "16815 2765 0.16443651501635445\n",
      "epoch 536, loss 95.72124481201172\n",
      "16815 2676 0.1591436217662801\n",
      "epoch 537, loss 96.47488403320312\n",
      "16815 2544 0.1512934879571811\n",
      "epoch 538, loss 95.1676254272461\n",
      "16815 2654 0.15783526613143026\n",
      "epoch 539, loss 95.68599700927734\n",
      "16815 2457 0.14611953612845674\n",
      "epoch 540, loss 96.46363830566406\n",
      "16815 2457 0.14611953612845674\n",
      "epoch 541, loss 95.413330078125\n",
      "16815 2701 0.16063038953315492\n",
      "epoch 542, loss 96.71964263916016\n",
      "16815 2470 0.14689265536723164\n",
      "epoch 543, loss 97.26591491699219\n",
      "16815 2536 0.15081772227178114\n",
      "epoch 544, loss 97.21624755859375\n",
      "16815 2446 0.14546535831103183\n",
      "epoch 545, loss 96.78614807128906\n",
      "16815 2402 0.14284864704133216\n",
      "epoch 546, loss 96.47882080078125\n",
      "16815 2408 0.1432054713053821\n",
      "epoch 547, loss 96.22845458984375\n",
      "16815 2469 0.14683318465655665\n",
      "epoch 548, loss 95.6528091430664\n",
      "16815 2559 0.152185548617306\n",
      "epoch 549, loss 94.60797882080078\n",
      "16815 2928 0.17413024085637824\n",
      "epoch 550, loss 95.7123031616211\n",
      "16815 2672 0.15890573892358015\n",
      "epoch 551, loss 96.54032897949219\n",
      "16815 2627 0.15622955694320548\n",
      "epoch 552, loss 94.69861602783203\n",
      "16815 2964 0.17627118644067796\n",
      "epoch 553, loss 97.1553955078125\n",
      "16815 2452 0.14582218257508178\n",
      "epoch 554, loss 95.71698760986328\n",
      "16815 2702 0.16068986024382992\n",
      "epoch 555, loss 97.3392105102539\n",
      "16815 2592 0.15414808206958072\n",
      "epoch 556, loss 96.48682403564453\n",
      "16815 2447 0.1455248290217068\n",
      "epoch 557, loss 95.60835266113281\n",
      "16815 2872 0.17079988105857866\n",
      "epoch 558, loss 94.50672149658203\n",
      "16815 2914 0.17329765090692834\n",
      "epoch 559, loss 95.65162658691406\n",
      "16815 2639 0.15694320547130539\n",
      "epoch 560, loss 95.40885925292969\n",
      "16815 2727 0.16217662801070473\n",
      "epoch 561, loss 98.70548248291016\n",
      "16815 2328 0.13844781445138268\n",
      "epoch 562, loss 97.3601303100586\n",
      "16815 2381 0.1415997621171573\n",
      "epoch 563, loss 96.90121459960938\n",
      "16815 2384 0.14177817424918226\n",
      "epoch 564, loss 96.52493286132812\n",
      "16815 2430 0.14451382694023193\n",
      "epoch 565, loss 96.26155853271484\n",
      "16815 2566 0.1526018435920309\n",
      "epoch 566, loss 95.86890411376953\n",
      "16815 2591 0.15408861135890575\n",
      "epoch 567, loss 95.49225616455078\n",
      "16815 2657 0.15801367826345525\n",
      "epoch 568, loss 94.89888000488281\n",
      "16815 2835 0.16859946476360393\n",
      "epoch 569, loss 93.59326934814453\n",
      "16815 3063 0.18215878679750222\n",
      "epoch 570, loss 97.34066772460938\n",
      "16815 2589 0.15396966993755576\n",
      "epoch 571, loss 95.99288177490234\n",
      "16815 2578 0.15331549212013085\n",
      "epoch 572, loss 93.45146179199219\n",
      "16815 3227 0.191911983348201\n",
      "epoch 573, loss 96.07318878173828\n",
      "16815 2743 0.1631281593815046\n",
      "epoch 574, loss 95.11702728271484\n",
      "16815 2756 0.1639012786202795\n",
      "epoch 575, loss 95.71849822998047\n",
      "16815 2630 0.15640796907523044\n",
      "epoch 576, loss 95.55006408691406\n",
      "16815 2616 0.15557537912578057\n",
      "epoch 577, loss 95.1998291015625\n",
      "16815 2604 0.15486173059768063\n",
      "epoch 578, loss 95.82803344726562\n",
      "16815 2519 0.14980672019030628\n",
      "epoch 579, loss 95.10999298095703\n",
      "16815 2756 0.1639012786202795\n",
      "epoch 580, loss 96.66951751708984\n",
      "16815 2536 0.15081772227178114\n",
      "epoch 581, loss 96.15771484375\n",
      "16815 2538 0.15093666369313113\n",
      "epoch 582, loss 94.5548095703125\n",
      "16815 2804 0.16675587273267917\n",
      "epoch 583, loss 95.22559356689453\n",
      "16815 2523 0.15004460303300624\n",
      "epoch 584, loss 97.27803802490234\n",
      "16815 2444 0.14534641688968183\n",
      "epoch 585, loss 95.81853485107422\n",
      "16815 2625 0.15611061552185548\n",
      "epoch 586, loss 97.75819396972656\n",
      "16815 2717 0.1615819209039548\n",
      "epoch 587, loss 97.92359161376953\n",
      "16815 2307 0.13719892952720786\n",
      "epoch 588, loss 97.163330078125\n",
      "16815 2457 0.14611953612845674\n",
      "epoch 589, loss 96.65609741210938\n",
      "16815 2521 0.14992566161165627\n",
      "epoch 590, loss 96.4070053100586\n",
      "16815 2531 0.15052036871840618\n",
      "epoch 591, loss 96.03942108154297\n",
      "16815 2563 0.15242343146000595\n",
      "epoch 592, loss 95.63961791992188\n",
      "16815 2735 0.16265239369610468\n",
      "epoch 593, loss 94.95870208740234\n",
      "16815 2973 0.1768064228367529\n",
      "epoch 594, loss 93.94650268554688\n",
      "16815 3140 0.18673803151947665\n",
      "epoch 595, loss 94.14501190185547\n",
      "16815 2876 0.17103776390127862\n",
      "epoch 596, loss 95.78517150878906\n",
      "16815 2638 0.1568837347606304\n",
      "epoch 597, loss 94.38917541503906\n",
      "16815 2847 0.16931311329170384\n",
      "epoch 598, loss 97.2373046875\n",
      "16815 2640 0.15700267618198038\n",
      "epoch 599, loss 95.6683349609375\n",
      "16815 2740 0.16294974724947964\n",
      "epoch 600, loss 95.5378189086914\n",
      "16815 2835 0.16859946476360393\n",
      "epoch 601, loss 97.93074798583984\n",
      "16815 2487 0.1479036574487065\n",
      "epoch 602, loss 96.45854949951172\n",
      "16815 2494 0.14831995242343146\n",
      "epoch 603, loss 94.77426147460938\n",
      "16815 2888 0.17175141242937852\n",
      "epoch 604, loss 94.98779296875\n",
      "16815 2882 0.17139458816532857\n",
      "epoch 605, loss 100.67447662353516\n",
      "16815 2337 0.13898305084745763\n",
      "epoch 606, loss 98.36793518066406\n",
      "16815 2263 0.13458221825750818\n",
      "epoch 607, loss 97.6983413696289\n",
      "16815 2325 0.13826940231935772\n",
      "epoch 608, loss 97.24129486083984\n",
      "16815 2393 0.1423134106452572\n",
      "epoch 609, loss 96.88877868652344\n",
      "16815 2444 0.14534641688968183\n",
      "epoch 610, loss 96.58515930175781\n",
      "16815 2399 0.14267023490930716\n",
      "epoch 611, loss 96.29768371582031\n",
      "16815 2486 0.1478441867380315\n",
      "epoch 612, loss 95.97264099121094\n",
      "16815 2501 0.1487362473981564\n",
      "epoch 613, loss 95.49227905273438\n",
      "16815 2720 0.16176033303597978\n",
      "epoch 614, loss 94.59536743164062\n",
      "16815 3018 0.17948260481712758\n",
      "epoch 615, loss 93.85431671142578\n",
      "16815 3012 0.1791257805530776\n",
      "epoch 616, loss 96.64520263671875\n",
      "16815 2631 0.15646743978590544\n",
      "epoch 617, loss 94.21239471435547\n",
      "16815 2795 0.16622063633660422\n",
      "epoch 618, loss 94.73243713378906\n",
      "16815 2723 0.16193874516800474\n",
      "epoch 619, loss 95.90107727050781\n",
      "16815 2697 0.16039250669045496\n",
      "epoch 620, loss 97.6229248046875\n",
      "16815 2622 0.15593220338983052\n",
      "epoch 621, loss 96.85824584960938\n",
      "16815 2429 0.14445435622955693\n",
      "epoch 622, loss 95.71685791015625\n",
      "16815 2615 0.15551590841510557\n",
      "epoch 623, loss 93.80319213867188\n",
      "16815 3015 0.1793041926851026\n",
      "epoch 624, loss 95.86604309082031\n",
      "16815 2620 0.15581326196848053\n",
      "epoch 625, loss 95.24504852294922\n",
      "16815 2717 0.1615819209039548\n",
      "epoch 626, loss 98.07777404785156\n",
      "16815 2380 0.1415402914064823\n",
      "epoch 627, loss 94.69976806640625\n",
      "16815 2835 0.16859946476360393\n",
      "epoch 628, loss 95.75505065917969\n",
      "16815 2636 0.1567647933392804\n",
      "epoch 629, loss 97.89757537841797\n",
      "16815 2489 0.1480225988700565\n",
      "epoch 630, loss 96.38025665283203\n",
      "16815 2433 0.14469223907225692\n",
      "epoch 631, loss 94.59188079833984\n",
      "16815 2913 0.17323818019625334\n",
      "epoch 632, loss 95.2160415649414\n",
      "16815 2529 0.1504014272970562\n",
      "epoch 633, loss 95.89661407470703\n",
      "16815 2556 0.152007136485281\n",
      "epoch 634, loss 95.12554168701172\n",
      "16815 2596 0.1543859649122807\n",
      "epoch 635, loss 95.40276336669922\n",
      "16815 2559 0.152185548617306\n",
      "epoch 636, loss 95.93132781982422\n",
      "16815 2607 0.15504014272970562\n",
      "epoch 637, loss 95.31099700927734\n",
      "16815 2644 0.15724055902468034\n",
      "epoch 638, loss 95.5901107788086\n",
      "16815 2601 0.15468331846565567\n",
      "epoch 639, loss 98.49651336669922\n",
      "16815 2453 0.14588165328575675\n",
      "epoch 640, loss 98.08505249023438\n",
      "16815 2233 0.1327980969372584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 641, loss 97.55810546875\n",
      "16815 2335 0.13886410942610763\n",
      "epoch 642, loss 97.0419692993164\n",
      "16815 2363 0.14052928932500744\n",
      "epoch 643, loss 96.782958984375\n",
      "16815 2404 0.14296758846268212\n",
      "epoch 644, loss 96.49201202392578\n",
      "16815 2475 0.1471900089206066\n",
      "epoch 645, loss 96.21121215820312\n",
      "16815 2444 0.14534641688968183\n",
      "epoch 646, loss 95.83984375\n",
      "16815 2708 0.16104668450787987\n",
      "epoch 647, loss 95.38361358642578\n",
      "16815 2770 0.1647338685697294\n",
      "epoch 648, loss 94.74862670898438\n",
      "16815 3084 0.18340767172167707\n",
      "epoch 649, loss 93.88282775878906\n",
      "16815 3027 0.1800178412132025\n",
      "epoch 650, loss 94.15995025634766\n",
      "16815 2787 0.16574487065120427\n",
      "epoch 651, loss 96.79724884033203\n",
      "16815 2580 0.1534344335414808\n",
      "epoch 652, loss 94.58895874023438\n",
      "16815 2655 0.15789473684210525\n",
      "epoch 653, loss 98.17227935791016\n",
      "16815 2399 0.14267023490930716\n",
      "epoch 654, loss 96.64491271972656\n",
      "16815 2536 0.15081772227178114\n",
      "epoch 655, loss 95.73114013671875\n",
      "16815 2544 0.1512934879571811\n",
      "epoch 656, loss 94.67378234863281\n",
      "16815 2902 0.17258400237882843\n",
      "epoch 657, loss 92.99175262451172\n",
      "16815 3139 0.18667856080880166\n",
      "epoch 658, loss 100.31608581542969\n",
      "16815 2471 0.14695212607790664\n",
      "epoch 659, loss 94.85017395019531\n",
      "16815 3021 0.17966101694915254\n",
      "epoch 660, loss 94.20310974121094\n",
      "16815 2921 0.1737139458816533\n",
      "epoch 661, loss 95.41966247558594\n",
      "16815 2599 0.15456437704430567\n",
      "epoch 662, loss 95.1534194946289\n",
      "16815 2661 0.1582515611061552\n",
      "epoch 663, loss 96.0468978881836\n",
      "16815 2606 0.15498067201903062\n",
      "epoch 664, loss 94.73194885253906\n",
      "16815 2746 0.1633065715135296\n",
      "epoch 665, loss 97.5385513305664\n",
      "16815 2465 0.1465953018138567\n",
      "epoch 666, loss 95.39865112304688\n",
      "16815 2743 0.1631281593815046\n",
      "epoch 667, loss 95.72644805908203\n",
      "16815 2905 0.17276241451085342\n",
      "epoch 668, loss 97.67825317382812\n",
      "16815 2364 0.14058876003568244\n",
      "epoch 669, loss 96.33479309082031\n",
      "16815 2510 0.14927148379423133\n",
      "epoch 670, loss 94.73375701904297\n",
      "16815 2831 0.16836158192090395\n",
      "epoch 671, loss 96.6248550415039\n",
      "16815 2569 0.1527802557240559\n",
      "epoch 672, loss 94.37847900390625\n",
      "16815 2862 0.17020517395182871\n",
      "epoch 673, loss 96.25965881347656\n",
      "16815 2493 0.14826048171275646\n",
      "epoch 674, loss 96.372802734375\n",
      "16815 2501 0.1487362473981564\n",
      "epoch 675, loss 97.50503540039062\n",
      "16815 2432 0.14463276836158193\n",
      "epoch 676, loss 96.6541748046875\n",
      "16815 2459 0.14623847754980673\n",
      "epoch 677, loss 96.19157409667969\n",
      "16815 2477 0.1473089503419566\n",
      "epoch 678, loss 95.18132019042969\n",
      "16815 2761 0.16419863217365446\n",
      "epoch 679, loss 94.21648406982422\n",
      "16815 2786 0.16568539994052928\n",
      "epoch 680, loss 94.41138458251953\n",
      "16815 2740 0.16294974724947964\n",
      "epoch 681, loss 97.1040267944336\n",
      "16815 2400 0.14272970561998216\n",
      "epoch 682, loss 95.81610107421875\n",
      "16815 2568 0.1527207850133809\n",
      "epoch 683, loss 94.62162780761719\n",
      "16815 2859 0.17002676181980375\n",
      "epoch 684, loss 98.3960189819336\n",
      "16815 2382 0.1416592328278323\n",
      "epoch 685, loss 96.6687240600586\n",
      "16815 2462 0.1464168896818317\n",
      "epoch 686, loss 96.17298889160156\n",
      "16815 2568 0.1527207850133809\n",
      "epoch 687, loss 95.51319885253906\n",
      "16815 2707 0.16098721379720488\n",
      "epoch 688, loss 93.81407928466797\n",
      "16815 3178 0.18899791852512637\n",
      "epoch 689, loss 97.92909240722656\n",
      "16815 2578 0.15331549212013085\n",
      "epoch 690, loss 93.4180908203125\n",
      "16815 2997 0.17823371989295272\n",
      "epoch 691, loss 100.20891571044922\n",
      "16815 2476 0.1472494796312816\n",
      "epoch 692, loss 98.39215087890625\n",
      "16815 2165 0.1287540886113589\n",
      "epoch 693, loss 97.46095275878906\n",
      "16815 2359 0.14029140648230745\n",
      "epoch 694, loss 97.07867431640625\n",
      "16815 2425 0.14421647338685697\n",
      "epoch 695, loss 96.6971435546875\n",
      "16815 2428 0.14439488551888194\n",
      "epoch 696, loss 96.4406509399414\n",
      "16815 2512 0.14939042521558132\n",
      "epoch 697, loss 96.13803100585938\n",
      "16815 2492 0.14820101100208147\n",
      "epoch 698, loss 95.7799301147461\n",
      "16815 2572 0.1529586678560809\n",
      "epoch 699, loss 95.29879760742188\n",
      "16815 2678 0.1592625631876301\n",
      "epoch 700, loss 93.98258209228516\n",
      "16815 3160 0.1879274457329765\n",
      "epoch 701, loss 93.4560546875\n",
      "16815 3051 0.1814451382694023\n",
      "epoch 702, loss 96.19599914550781\n",
      "16815 2726 0.16211715730002974\n",
      "epoch 703, loss 94.63561248779297\n",
      "16815 2634 0.15664585191793043\n",
      "epoch 704, loss 94.80728912353516\n",
      "16815 2815 0.16741005055010408\n",
      "epoch 705, loss 95.24353790283203\n",
      "16815 2628 0.15628902765388047\n",
      "epoch 706, loss 95.48567962646484\n",
      "16815 2671 0.15884626821290515\n",
      "epoch 707, loss 95.38607788085938\n",
      "16815 2715 0.16146297948260482\n",
      "epoch 708, loss 94.794921875\n",
      "16815 2797 0.16633957775795422\n",
      "epoch 709, loss 97.12064361572266\n",
      "16815 2548 0.15153137079988105\n",
      "epoch 710, loss 96.46873474121094\n",
      "16815 2472 0.1470115967885816\n",
      "epoch 711, loss 95.7060317993164\n",
      "16815 2653 0.1577757954207553\n",
      "epoch 712, loss 94.7654800415039\n",
      "16815 2840 0.1688968183169789\n",
      "epoch 713, loss 95.35492706298828\n",
      "16815 2585 0.15373178709485577\n",
      "epoch 714, loss 96.13426971435547\n",
      "16815 2612 0.15533749628308058\n",
      "epoch 715, loss 94.36492919921875\n",
      "16815 2767 0.16455545643770442\n",
      "epoch 716, loss 97.88076782226562\n",
      "16815 2413 0.14350282485875707\n",
      "epoch 717, loss 95.45732879638672\n",
      "16815 2597 0.1544454356229557\n",
      "epoch 718, loss 94.8197021484375\n",
      "16815 2805 0.16681534344335414\n",
      "epoch 719, loss 97.1957778930664\n",
      "16815 2564 0.15248290217068095\n",
      "epoch 720, loss 96.18052673339844\n",
      "16815 2517 0.14968777876895628\n",
      "epoch 721, loss 94.85738372802734\n",
      "16815 2879 0.1712161760333036\n",
      "epoch 722, loss 96.32539367675781\n",
      "16815 2698 0.16045197740112993\n",
      "epoch 723, loss 94.4731674194336\n",
      "16815 2770 0.1647338685697294\n",
      "epoch 724, loss 97.76514434814453\n",
      "16815 2507 0.14909307166220637\n",
      "epoch 725, loss 96.51194763183594\n",
      "16815 2438 0.14498959262563188\n",
      "epoch 726, loss 95.84183502197266\n",
      "16815 2490 0.1480820695807315\n",
      "epoch 727, loss 94.19998931884766\n",
      "16815 3031 0.18025572405590246\n",
      "epoch 728, loss 95.14656829833984\n",
      "16815 2598 0.15450490633363068\n",
      "epoch 729, loss 96.32550048828125\n",
      "16815 2670 0.15878679750223015\n",
      "epoch 730, loss 94.3005599975586\n",
      "16815 2681 0.15944097531965506\n",
      "epoch 731, loss 96.70165252685547\n",
      "16815 2569 0.1527802557240559\n",
      "epoch 732, loss 94.37411499023438\n",
      "16815 2898 0.17234611953612847\n",
      "epoch 733, loss 97.8771743774414\n",
      "16815 2474 0.1471305382099316\n",
      "epoch 734, loss 95.5806884765625\n",
      "16815 2595 0.1543264942016057\n",
      "epoch 735, loss 94.36136627197266\n",
      "16815 2933 0.1744275944097532\n",
      "epoch 736, loss 95.09959411621094\n",
      "16815 2648 0.1574784418673803\n",
      "epoch 737, loss 94.80517578125\n",
      "16815 2690 0.15997621171573\n",
      "epoch 738, loss 95.89102172851562\n",
      "16815 2576 0.15319655069878085\n",
      "epoch 739, loss 95.46931457519531\n",
      "16815 2650 0.1575973832887303\n",
      "epoch 740, loss 97.0718765258789\n",
      "16815 2576 0.15319655069878085\n",
      "epoch 741, loss 95.38522338867188\n",
      "16815 2791 0.16598275349390426\n",
      "epoch 742, loss 94.04438781738281\n",
      "16815 2837 0.1687184061849539\n",
      "epoch 743, loss 96.6890640258789\n",
      "16815 2554 0.151888195063931\n",
      "epoch 744, loss 93.85657501220703\n",
      "16815 2792 0.16604222420457926\n",
      "epoch 745, loss 96.0567398071289\n",
      "16815 2546 0.15141242937853108\n",
      "epoch 746, loss 97.00265502929688\n",
      "16815 2560 0.15224501932798096\n",
      "epoch 747, loss 96.21896362304688\n",
      "16815 2520 0.14986619090098127\n",
      "epoch 748, loss 95.17262268066406\n",
      "16815 2786 0.16568539994052928\n",
      "epoch 749, loss 93.53343963623047\n",
      "16815 2840 0.1688968183169789\n",
      "epoch 750, loss 101.83895111083984\n",
      "16815 2235 0.13291703835860838\n",
      "epoch 751, loss 98.82511138916016\n",
      "16815 2123 0.12625631876300922\n",
      "epoch 752, loss 97.77865600585938\n",
      "16815 2248 0.13369015759738329\n",
      "epoch 753, loss 97.35079193115234\n",
      "16815 2398 0.14261076419863217\n",
      "epoch 754, loss 97.0789566040039\n",
      "16815 2350 0.13975617008623253\n",
      "epoch 755, loss 96.8437728881836\n",
      "16815 2426 0.14427594409753197\n",
      "epoch 756, loss 96.62976837158203\n",
      "16815 2422 0.14403806125483198\n",
      "epoch 757, loss 96.46466064453125\n",
      "16815 2429 0.14445435622955693\n",
      "epoch 758, loss 96.2614974975586\n",
      "16815 2525 0.15016354445435623\n",
      "epoch 759, loss 95.982177734375\n",
      "16815 2540 0.15105560511448113\n",
      "epoch 760, loss 95.78852081298828\n",
      "16815 2562 0.15236396074933095\n",
      "epoch 761, loss 95.51641845703125\n",
      "16815 2613 0.15539696699375558\n",
      "epoch 762, loss 95.11048889160156\n",
      "16815 2698 0.16045197740112993\n",
      "epoch 763, loss 94.7596206665039\n",
      "16815 2852 0.1696104668450788\n",
      "epoch 764, loss 94.20601654052734\n",
      "16815 2931 0.1743086529884032\n",
      "epoch 765, loss 93.94747924804688\n",
      "16815 2969 0.17656853999405292\n",
      "epoch 766, loss 93.6026611328125\n",
      "16815 2860 0.17008623253047875\n",
      "epoch 767, loss 94.44677734375\n",
      "16815 2830 0.16830211121022895\n",
      "epoch 768, loss 94.34150695800781\n",
      "16815 2694 0.16021409455842997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 769, loss 96.28457641601562\n",
      "16815 2674 0.1590246803449301\n",
      "epoch 770, loss 93.53534698486328\n",
      "16815 2803 0.16669640202200417\n",
      "epoch 771, loss 95.9163589477539\n",
      "16815 2616 0.15557537912578057\n",
      "epoch 772, loss 97.96330261230469\n",
      "16815 2430 0.14451382694023193\n",
      "epoch 773, loss 94.9875259399414\n",
      "16815 2790 0.16592328278322926\n",
      "epoch 774, loss 94.14447021484375\n",
      "16815 3138 0.18661909009812666\n",
      "epoch 775, loss 95.05043029785156\n",
      "16815 2706 0.16092774308652988\n",
      "epoch 776, loss 96.19292449951172\n",
      "16815 2630 0.15640796907523044\n",
      "epoch 777, loss 97.7852554321289\n",
      "16815 2719 0.16170086232530478\n",
      "epoch 778, loss 97.65542602539062\n",
      "16815 2322 0.13809099018733273\n",
      "epoch 779, loss 96.71284484863281\n",
      "16815 2519 0.14980672019030628\n",
      "epoch 780, loss 95.98308563232422\n",
      "16815 2488 0.1479631281593815\n",
      "epoch 781, loss 95.13438415527344\n",
      "16815 2671 0.15884626821290515\n",
      "epoch 782, loss 93.45994567871094\n",
      "16815 3185 0.18941421349985132\n",
      "epoch 783, loss 94.6024169921875\n",
      "16815 2782 0.16544751709782932\n",
      "epoch 784, loss 99.210205078125\n",
      "16815 2484 0.14772524531668155\n",
      "epoch 785, loss 96.82801055908203\n",
      "16815 2486 0.1478441867380315\n",
      "epoch 786, loss 95.67813873291016\n",
      "16815 2527 0.15028248587570622\n",
      "epoch 787, loss 94.48869323730469\n",
      "16815 2831 0.16836158192090395\n",
      "epoch 788, loss 92.9472427368164\n",
      "16815 3105 0.18465655664585193\n",
      "epoch 789, loss 95.67488098144531\n",
      "16815 2857 0.16990782039845376\n",
      "epoch 790, loss 98.0323486328125\n",
      "16815 2433 0.14469223907225692\n",
      "epoch 791, loss 94.8652114868164\n",
      "16815 2890 0.17187035385072852\n",
      "epoch 792, loss 93.90853881835938\n",
      "16815 2875 0.17097829319060362\n",
      "epoch 793, loss 94.88068389892578\n",
      "16815 2841 0.1689562890276539\n",
      "epoch 794, loss 95.02913665771484\n",
      "16815 2667 0.15860838537020516\n",
      "epoch 795, loss 97.97084045410156\n",
      "16815 2453 0.14588165328575675\n",
      "epoch 796, loss 96.2980728149414\n",
      "16815 2494 0.14831995242343146\n",
      "epoch 797, loss 94.34590911865234\n",
      "16815 3009 0.17894736842105263\n",
      "epoch 798, loss 95.894287109375\n",
      "16815 2574 0.15307760927743086\n",
      "epoch 799, loss 95.3240737915039\n",
      "16815 2785 0.1656259292298543\n",
      "epoch 800, loss 94.7675552368164\n",
      "16815 2832 0.16842105263157894\n",
      "epoch 801, loss 96.59125518798828\n",
      "16815 2526 0.15022301516503123\n",
      "epoch 802, loss 95.27938842773438\n",
      "16815 2826 0.168064228367529\n",
      "epoch 803, loss 96.71360778808594\n",
      "16815 2448 0.1455842997323818\n",
      "epoch 804, loss 95.36528778076172\n",
      "16815 2700 0.16057091882247992\n",
      "epoch 805, loss 96.7297134399414\n",
      "16815 2679 0.15932203389830507\n",
      "epoch 806, loss 96.11985778808594\n",
      "16815 2512 0.14939042521558132\n",
      "epoch 807, loss 94.74098205566406\n",
      "16815 2783 0.1655069878085043\n",
      "epoch 808, loss 93.91543579101562\n",
      "16815 2819 0.16764793339280404\n",
      "epoch 809, loss 94.0850601196289\n",
      "16815 2699 0.16051144811180493\n",
      "epoch 810, loss 95.92749786376953\n",
      "16815 2651 0.1576568539994053\n",
      "epoch 811, loss 94.25035858154297\n",
      "16815 2813 0.16729110912875408\n",
      "epoch 812, loss 94.75848388671875\n",
      "16815 2620 0.15581326196848053\n",
      "epoch 813, loss 94.92282104492188\n",
      "16815 2630 0.15640796907523044\n",
      "epoch 814, loss 94.66466522216797\n",
      "16815 2685 0.15967885816235505\n",
      "epoch 815, loss 95.13359832763672\n",
      "16815 2689 0.159916741005055\n",
      "epoch 816, loss 96.18736267089844\n",
      "16815 2590 0.15402914064823076\n",
      "epoch 817, loss 94.96273803710938\n",
      "16815 2714 0.16140350877192983\n",
      "epoch 818, loss 95.36865234375\n",
      "16815 2704 0.1608088016651799\n",
      "epoch 819, loss 96.938232421875\n",
      "16815 2521 0.14992566161165627\n",
      "epoch 820, loss 96.21297454833984\n",
      "16815 2572 0.1529586678560809\n",
      "epoch 821, loss 95.31065368652344\n",
      "16815 2639 0.15694320547130539\n",
      "epoch 822, loss 95.55760192871094\n",
      "16815 2716 0.16152245019327982\n",
      "epoch 823, loss 93.93805694580078\n",
      "16815 2995 0.17811477847160273\n",
      "epoch 824, loss 95.79118347167969\n",
      "16815 2598 0.15450490633363068\n",
      "epoch 825, loss 94.30101013183594\n",
      "16815 2858 0.16996729110912875\n",
      "epoch 826, loss 98.51779174804688\n",
      "16815 2286 0.135950044603033\n",
      "epoch 827, loss 96.16796875\n",
      "16815 2553 0.15182872435325603\n",
      "epoch 828, loss 95.3305435180664\n",
      "16815 2697 0.16039250669045496\n",
      "epoch 829, loss 94.88560485839844\n",
      "16815 3013 0.1791852512637526\n",
      "epoch 830, loss 94.54061126708984\n",
      "16815 2819 0.16764793339280404\n",
      "epoch 831, loss 94.8297119140625\n",
      "16815 2736 0.16271186440677965\n",
      "epoch 832, loss 96.59717559814453\n",
      "16815 2616 0.15557537912578057\n",
      "epoch 833, loss 96.48332977294922\n",
      "16815 2557 0.152066607195956\n",
      "epoch 834, loss 95.62216186523438\n",
      "16815 2525 0.15016354445435623\n",
      "epoch 835, loss 94.0434341430664\n",
      "16815 2980 0.17722271781147786\n",
      "epoch 836, loss 94.92601013183594\n",
      "16815 2701 0.16063038953315492\n",
      "epoch 837, loss 94.5087890625\n",
      "16815 2717 0.1615819209039548\n",
      "epoch 838, loss 99.88046264648438\n",
      "16815 2285 0.135890573892358\n",
      "epoch 839, loss 96.63594818115234\n",
      "16815 2456 0.14606006541778174\n",
      "epoch 840, loss 96.15126037597656\n",
      "16815 2558 0.152126077906631\n",
      "epoch 841, loss 95.66512298583984\n",
      "16815 2552 0.15176925364258104\n",
      "epoch 842, loss 94.8755874633789\n",
      "16815 2765 0.16443651501635445\n",
      "epoch 843, loss 93.15180969238281\n",
      "16815 3097 0.18418079096045198\n",
      "epoch 844, loss 96.24208068847656\n",
      "16815 2607 0.15504014272970562\n",
      "epoch 845, loss 94.1349868774414\n",
      "16815 2984 0.17746060065417782\n",
      "epoch 846, loss 94.29058074951172\n",
      "16815 2718 0.1616413916146298\n",
      "epoch 847, loss 95.14498138427734\n",
      "16815 2826 0.168064228367529\n",
      "epoch 848, loss 96.28953552246094\n",
      "16815 2702 0.16068986024382992\n",
      "epoch 849, loss 95.77867889404297\n",
      "16815 2797 0.16633957775795422\n",
      "epoch 850, loss 94.40116882324219\n",
      "16815 2880 0.17127564674397858\n",
      "epoch 851, loss 96.78047943115234\n",
      "16815 2532 0.15057983942908118\n",
      "epoch 852, loss 95.28367614746094\n",
      "16815 2611 0.15527802557240558\n",
      "epoch 853, loss 94.13136291503906\n",
      "16815 2912 0.17317870948557834\n",
      "epoch 854, loss 95.39376831054688\n",
      "16815 2569 0.1527802557240559\n",
      "epoch 855, loss 93.98519134521484\n",
      "16815 2750 0.16354445435622955\n",
      "epoch 856, loss 97.72045135498047\n",
      "16815 2506 0.14903360095153137\n",
      "epoch 857, loss 95.90271759033203\n",
      "16815 2631 0.15646743978590544\n",
      "epoch 858, loss 94.4969253540039\n",
      "16815 3004 0.17865001486767768\n",
      "epoch 859, loss 95.59513854980469\n",
      "16815 2804 0.16675587273267917\n",
      "epoch 860, loss 94.89397430419922\n",
      "16815 2833 0.16848052334225394\n",
      "epoch 861, loss 96.16494750976562\n",
      "16815 2630 0.15640796907523044\n",
      "epoch 862, loss 94.2483139038086\n",
      "16815 2953 0.17561700862325305\n",
      "epoch 863, loss 94.18080139160156\n",
      "16815 2776 0.16509069283377936\n",
      "epoch 864, loss 94.89080047607422\n",
      "16815 2666 0.1585489146595302\n",
      "epoch 865, loss 95.12870025634766\n",
      "16815 2609 0.15515908415105562\n",
      "epoch 866, loss 97.12632751464844\n",
      "16815 2607 0.15504014272970562\n",
      "epoch 867, loss 99.2923812866211\n",
      "16815 2129 0.12661314302705917\n",
      "epoch 868, loss 97.35718536376953\n",
      "16815 2419 0.14385964912280702\n",
      "epoch 869, loss 96.81340789794922\n",
      "16815 2392 0.1422539399345822\n",
      "epoch 870, loss 96.4897689819336\n",
      "16815 2454 0.14594112399643175\n",
      "epoch 871, loss 96.10370635986328\n",
      "16815 2564 0.15248290217068095\n",
      "epoch 872, loss 95.88042449951172\n",
      "16815 2618 0.15569432054713053\n",
      "epoch 873, loss 95.32400512695312\n",
      "16815 2736 0.16271186440677965\n",
      "epoch 874, loss 94.66566467285156\n",
      "16815 2936 0.17460600654177819\n",
      "epoch 875, loss 93.50703430175781\n",
      "16815 3279 0.19500446030330063\n",
      "epoch 876, loss 92.24085998535156\n",
      "16815 2961 0.176092774308653\n",
      "epoch 877, loss 100.38158416748047\n",
      "16815 2634 0.15664585191793043\n",
      "epoch 878, loss 92.53121185302734\n",
      "16815 3332 0.19815640796907524\n",
      "epoch 879, loss 99.09738159179688\n",
      "16815 3031 0.18025572405590246\n",
      "epoch 880, loss 101.3992919921875\n",
      "16815 1993 0.11852512637526018\n",
      "epoch 881, loss 98.49192810058594\n",
      "16815 2279 0.13553374962830805\n",
      "epoch 882, loss 97.73650360107422\n",
      "16815 2359 0.14029140648230745\n",
      "epoch 883, loss 97.2259750366211\n",
      "16815 2401 0.14278917633065716\n",
      "epoch 884, loss 96.94367980957031\n",
      "16815 2474 0.1471305382099316\n",
      "epoch 885, loss 96.37100219726562\n",
      "16815 2446 0.14546535831103183\n",
      "epoch 886, loss 95.84867858886719\n",
      "16815 2494 0.14831995242343146\n",
      "epoch 887, loss 95.49079132080078\n",
      "16815 2615 0.15551590841510557\n",
      "epoch 888, loss 94.70206451416016\n",
      "16815 2834 0.16853999405292894\n",
      "epoch 889, loss 93.73503112792969\n",
      "16815 3204 0.19054415700267618\n",
      "epoch 890, loss 92.71226501464844\n",
      "16815 3288 0.19553969669937557\n",
      "epoch 891, loss 93.22152709960938\n",
      "16815 2681 0.15944097531965506\n",
      "epoch 892, loss 93.57429504394531\n",
      "16815 2927 0.17407077014570324\n",
      "epoch 893, loss 92.96368408203125\n",
      "16815 2964 0.17627118644067796\n",
      "epoch 894, loss 94.16299438476562\n",
      "16815 2940 0.17484388938447815\n",
      "epoch 895, loss 94.48001098632812\n",
      "16815 2770 0.1647338685697294\n",
      "epoch 896, loss 94.43046569824219\n",
      "16815 2764 0.16437704430567945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 897, loss 93.90155029296875\n",
      "16815 2735 0.16265239369610468\n",
      "epoch 898, loss 96.34032440185547\n",
      "16815 2619 0.15575379125780553\n",
      "epoch 899, loss 94.6413803100586\n",
      "16815 2684 0.15961938745168006\n",
      "epoch 900, loss 94.35651397705078\n",
      "16815 2664 0.1584299732381802\n",
      "epoch 901, loss 95.19133758544922\n",
      "16815 2692 0.16009515313707998\n",
      "epoch 902, loss 94.82492065429688\n",
      "16815 2737 0.16277133511745465\n",
      "epoch 903, loss 94.5623550415039\n",
      "16815 2662 0.1583110318168302\n",
      "epoch 904, loss 95.70182037353516\n",
      "16815 2693 0.16015462384775497\n",
      "epoch 905, loss 98.69187927246094\n",
      "16815 2272 0.1351174546535831\n",
      "epoch 906, loss 97.21540069580078\n",
      "16815 2492 0.14820101100208147\n",
      "epoch 907, loss 96.53838348388672\n",
      "16815 2524 0.15010407374368123\n",
      "epoch 908, loss 95.99845123291016\n",
      "16815 2514 0.14950936663693132\n",
      "epoch 909, loss 95.30433654785156\n",
      "16815 2643 0.15718108831400535\n",
      "epoch 910, loss 94.17428588867188\n",
      "16815 2971 0.1766874814154029\n",
      "epoch 911, loss 92.49412536621094\n",
      "16815 3204 0.19054415700267618\n",
      "epoch 912, loss 94.50562286376953\n",
      "16815 2820 0.16770740410347904\n",
      "epoch 913, loss 94.0936508178711\n",
      "16815 2728 0.16223609872137973\n",
      "epoch 914, loss 95.79985809326172\n",
      "16815 2609 0.15515908415105562\n",
      "epoch 915, loss 97.40797424316406\n",
      "16815 2676 0.1591436217662801\n",
      "epoch 916, loss 97.54475402832031\n",
      "16815 2397 0.14255129348795717\n",
      "epoch 917, loss 96.63497161865234\n",
      "16815 2496 0.14843889384478146\n",
      "epoch 918, loss 95.93983459472656\n",
      "16815 2579 0.15337496283080582\n",
      "epoch 919, loss 94.81953430175781\n",
      "16815 2797 0.16633957775795422\n",
      "epoch 920, loss 92.5044174194336\n",
      "16815 3163 0.18810585786500147\n",
      "epoch 921, loss 95.26853942871094\n",
      "16815 2849 0.1694320547130538\n",
      "epoch 922, loss 94.4974365234375\n",
      "16815 2768 0.16461492714837941\n",
      "epoch 923, loss 96.97026824951172\n",
      "16815 2545 0.15135295866785609\n",
      "epoch 924, loss 94.03413391113281\n",
      "16815 2966 0.17639012786202796\n",
      "epoch 925, loss 93.8380126953125\n",
      "16815 2770 0.1647338685697294\n",
      "epoch 926, loss 100.27941131591797\n",
      "16815 2355 0.1400535236396075\n",
      "epoch 927, loss 98.09779357910156\n",
      "16815 2340 0.1391614629794826\n",
      "epoch 928, loss 97.4797134399414\n",
      "16815 2334 0.13880463871543264\n",
      "epoch 929, loss 97.03421020507812\n",
      "16815 2454 0.14594112399643175\n",
      "epoch 930, loss 96.72901153564453\n",
      "16815 2521 0.14992566161165627\n",
      "epoch 931, loss 96.44547271728516\n",
      "16815 2479 0.14742789176330656\n",
      "epoch 932, loss 96.00285339355469\n",
      "16815 2569 0.1527802557240559\n",
      "epoch 933, loss 95.57164001464844\n",
      "16815 2597 0.1544454356229557\n",
      "epoch 934, loss 94.79642486572266\n",
      "16815 2856 0.16984834968777876\n",
      "epoch 935, loss 93.6623306274414\n",
      "16815 3138 0.18661909009812666\n",
      "epoch 936, loss 92.3517837524414\n",
      "16815 3150 0.1873327386262266\n",
      "epoch 937, loss 98.67797088623047\n",
      "16815 2894 0.17210823669342848\n",
      "epoch 938, loss 91.75359344482422\n",
      "16815 3364 0.20005947071067498\n",
      "epoch 939, loss 93.49371337890625\n",
      "16815 2888 0.17175141242937852\n",
      "epoch 940, loss 95.93128967285156\n",
      "16815 2841 0.1689562890276539\n",
      "epoch 941, loss 96.06732177734375\n",
      "16815 2808 0.16699375557537913\n",
      "epoch 942, loss 96.64108276367188\n",
      "16815 2500 0.14867677668748142\n",
      "epoch 943, loss 92.71957397460938\n",
      "16815 3125 0.18584597085935176\n",
      "epoch 944, loss 97.7520980834961\n",
      "16815 2452 0.14582218257508178\n",
      "epoch 945, loss 93.87913513183594\n",
      "16815 2953 0.17561700862325305\n",
      "epoch 946, loss 95.13910675048828\n",
      "16815 2689 0.159916741005055\n",
      "epoch 947, loss 98.2113265991211\n",
      "16815 2456 0.14606006541778174\n",
      "epoch 948, loss 97.7109375\n",
      "16815 2267 0.13482010110020815\n",
      "epoch 949, loss 97.17646789550781\n",
      "16815 2437 0.14493012191495688\n",
      "epoch 950, loss 96.51568603515625\n",
      "16815 2431 0.14457329765090693\n",
      "epoch 951, loss 95.8780288696289\n",
      "16815 2527 0.15028248587570622\n",
      "epoch 952, loss 94.76030731201172\n",
      "16815 2870 0.17068093963722866\n",
      "epoch 953, loss 92.36210632324219\n",
      "16815 3097 0.18418079096045198\n",
      "epoch 954, loss 94.58779907226562\n",
      "16815 2823 0.16788581623550403\n",
      "epoch 955, loss 96.65731048583984\n",
      "16815 2657 0.15801367826345525\n",
      "epoch 956, loss 94.40780639648438\n",
      "16815 2784 0.1655664585191793\n",
      "epoch 957, loss 95.52973937988281\n",
      "16815 2752 0.16366339577757955\n",
      "epoch 958, loss 96.20050811767578\n",
      "16815 2491 0.14814154029140647\n",
      "epoch 959, loss 93.75428771972656\n",
      "16815 2991 0.17787689562890277\n",
      "epoch 960, loss 97.81316375732422\n",
      "16815 2555 0.151947665774606\n",
      "epoch 961, loss 94.60515594482422\n",
      "16815 2884 0.17151352958667856\n",
      "epoch 962, loss 94.32524871826172\n",
      "16815 2833 0.16848052334225394\n",
      "epoch 963, loss 96.76578521728516\n",
      "16815 2670 0.15878679750223015\n",
      "epoch 964, loss 94.17724609375\n",
      "16815 3039 0.1807314897413024\n",
      "epoch 965, loss 95.70972442626953\n",
      "16815 2693 0.16015462384775497\n",
      "epoch 966, loss 93.68299102783203\n",
      "16815 2930 0.17424918227772823\n",
      "epoch 967, loss 95.75464630126953\n",
      "16815 2677 0.1592030924769551\n",
      "epoch 968, loss 95.11524200439453\n",
      "16815 2807 0.16693428486470413\n",
      "epoch 969, loss 93.76628875732422\n",
      "16815 2791 0.16598275349390426\n",
      "epoch 970, loss 96.64878845214844\n",
      "16815 2585 0.15373178709485577\n",
      "epoch 971, loss 93.23961639404297\n",
      "16815 3043 0.1809693725840024\n",
      "epoch 972, loss 97.89559173583984\n",
      "16815 2521 0.14992566161165627\n",
      "epoch 973, loss 96.46049499511719\n",
      "16815 2544 0.1512934879571811\n",
      "epoch 974, loss 95.49798583984375\n",
      "16815 2675 0.1590841510556051\n",
      "epoch 975, loss 93.56753540039062\n",
      "16815 3122 0.1856675587273268\n",
      "epoch 976, loss 95.62852478027344\n",
      "16815 2682 0.15950044603033006\n",
      "epoch 977, loss 95.40855407714844\n",
      "16815 2670 0.15878679750223015\n",
      "epoch 978, loss 95.12284851074219\n",
      "16815 2922 0.17377341659232828\n",
      "epoch 979, loss 94.04954528808594\n",
      "16815 2910 0.17305976806422838\n",
      "epoch 980, loss 97.30204772949219\n",
      "16815 2499 0.14861730597680642\n",
      "epoch 981, loss 94.70184326171875\n",
      "16815 2840 0.1688968183169789\n",
      "epoch 982, loss 95.8338394165039\n",
      "16815 2714 0.16140350877192983\n",
      "epoch 983, loss 96.06072235107422\n",
      "16815 2779 0.16526910496580435\n",
      "epoch 984, loss 95.7057876586914\n",
      "16815 2699 0.16051144811180493\n",
      "epoch 985, loss 96.33177185058594\n",
      "16815 2972 0.1767469521260779\n",
      "epoch 986, loss 97.00889587402344\n",
      "16815 2452 0.14582218257508178\n",
      "epoch 987, loss 96.13092803955078\n",
      "16815 2472 0.1470115967885816\n",
      "epoch 988, loss 95.19692993164062\n",
      "16815 2522 0.14998513232233124\n",
      "epoch 989, loss 93.61360168457031\n",
      "16815 3052 0.1815046089800773\n",
      "epoch 990, loss 93.53778839111328\n",
      "16815 2954 0.17567647933392805\n",
      "epoch 991, loss 95.871826171875\n",
      "16815 2645 0.15730002973535534\n",
      "epoch 992, loss 93.92650604248047\n",
      "16815 2867 0.1705025275052037\n",
      "epoch 993, loss 96.30500030517578\n",
      "16815 2587 0.15385072851620576\n",
      "epoch 994, loss 95.56295776367188\n",
      "16815 2941 0.17490336009515314\n",
      "epoch 995, loss 96.88909149169922\n",
      "16815 2497 0.14849836455545642\n",
      "epoch 996, loss 95.58853149414062\n",
      "16815 2591 0.15408861135890575\n",
      "epoch 997, loss 92.93633270263672\n",
      "16815 3120 0.1855486173059768\n",
      "epoch 998, loss 95.15955352783203\n",
      "16815 2617 0.15563484983645554\n",
      "epoch 999, loss 96.25096130371094\n",
      "16815 2699 0.16051144811180493\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction='mean')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01) \n",
    "\n",
    "PRINT_RATE = 20\n",
    "\n",
    "## Optimization Loop\n",
    "\n",
    "for epoch in range(1000): \n",
    "    loss_sum = 0\n",
    "    total, correct = 0, 0\n",
    "    for idx, (x_batch, y_batch) in enumerate(dataloader):\n",
    "        y_pred = model(x_batch)\n",
    "        loss = criterion(y_pred, y_batch.long())\n",
    "        optimizer.zero_grad() \n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        loss_sum += loss\n",
    "        y_pred_i = torch.argmax(y_pred, dim=-1)\n",
    "        correct += torch.sum(torch.eq(y_pred_i, y_batch)).item()\n",
    "        total += len(y_batch)\n",
    "    print('epoch {}, loss {}'.format(epoch, loss_sum.item())) \n",
    "    print(total, correct, correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
